{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7994ea75",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-17T09:23:26.720138Z",
     "iopub.status.busy": "2024-12-17T09:23:26.718930Z",
     "iopub.status.idle": "2024-12-17T09:23:26.729654Z",
     "shell.execute_reply": "2024-12-17T09:23:26.728585Z"
    },
    "papermill": {
     "duration": 0.017838,
     "end_time": "2024-12-17T09:23:26.732037",
     "exception": false,
     "start_time": "2024-12-17T09:23:26.714199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43fdd657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T09:23:26.739326Z",
     "iopub.status.busy": "2024-12-17T09:23:26.738339Z",
     "iopub.status.idle": "2024-12-17T09:23:42.885624Z",
     "shell.execute_reply": "2024-12-17T09:23:42.884369Z"
    },
    "papermill": {
     "duration": 16.153396,
     "end_time": "2024-12-17T09:23:42.888167",
     "exception": false,
     "start_time": "2024-12-17T09:23:26.734771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score, average_precision_score, fbeta_score, matthews_corrcoef\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, Input, Conv1D, Lambda, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc3721ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T09:23:42.894761Z",
     "iopub.status.busy": "2024-12-17T09:23:42.894120Z",
     "iopub.status.idle": "2024-12-17T09:23:42.907159Z",
     "shell.execute_reply": "2024-12-17T09:23:42.906044Z"
    },
    "papermill": {
     "duration": 0.018817,
     "end_time": "2024-12-17T09:23:42.909443",
     "exception": false,
     "start_time": "2024-12-17T09:23:42.890626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convnext_like_model(input_dim, num_classes, sliding_window_size=3):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Reshape input to be compatible with Conv1D using Lambda layer\n",
    "    reshaped_input = Lambda(lambda x: tf.expand_dims(x, axis=-1))(input_layer)  # Shape: (batch_size, input_dim, 1)\n",
    "    x = reshaped_input\n",
    "    \n",
    "    # Simulate ConvNeXt block using Conv1D layers\n",
    "    x = Conv1D(filters=input_dim, kernel_size=sliding_window_size, padding='same', activation='gelu', strides=1)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Conv1D(filters=(input_dim * 2), kernel_size=sliding_window_size, padding='same', activation='gelu', strides=1)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Conv1D(filters=(input_dim * 4), kernel_size=sliding_window_size, padding='same', activation='gelu', strides=1)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Conv1D(filters=(input_dim * 8), kernel_size=sliding_window_size, padding='same', activation='gelu', strides=1)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Flatten the output of the final Conv1D layer\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Global pooling and classification head\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "520b15b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T09:23:42.932762Z",
     "iopub.status.busy": "2024-12-17T09:23:42.932113Z",
     "iopub.status.idle": "2024-12-17T09:23:42.948215Z",
     "shell.execute_reply": "2024-12-17T09:23:42.947043Z"
    },
    "papermill": {
     "duration": 0.022126,
     "end_time": "2024-12-17T09:23:42.950611",
     "exception": false,
     "start_time": "2024-12-17T09:23:42.928485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(train_data_path, test_data_path, is_string_labels = False, label_mapping = None):\n",
    "\n",
    "    # Initialize the one-hot encoder for the target\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Load and Prepare Training Data\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        train_data['label'] = train_data['label'].map(label_mapping)\n",
    "    train_X = train_data.drop(columns=['label']).values\n",
    "    train_y = train_data['label'].values\n",
    "    train_y = encoder.fit_transform(train_y.reshape(-1, 1))\n",
    "    del train_data\n",
    "    gc.collect()\n",
    "\n",
    "    # Load and Prepare Test Data (this will not be used in training)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    test_data = test_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        test_data['label'] = test_data['label'].map(label_mapping)\n",
    "    test_X = test_data.drop(columns=['label']).values\n",
    "    test_y = test_data['label'].values\n",
    "    test_y = encoder.transform(test_y.reshape(-1, 1))\n",
    "    del test_data\n",
    "    gc.collect()\n",
    "\n",
    "    # EarlyStopping Callback (optional, to avoid overfitting)\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Number of runs for averaging results\n",
    "    num_runs = 10\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    metrics_storage = defaultdict(list)\n",
    "\n",
    "    # Train the Model with Validation Split N tines for more accurate metrics\n",
    "    #print(\"Verbose output only for first run...\")\n",
    "    verbose_run = 0\n",
    "    for run in range(num_runs):\n",
    "        \n",
    "        # Model is defined separately in each run, since the random combination layers\n",
    "        # must be randomly initialized each time. Otherwise, the \"random\" indices stay the same\n",
    "        # throughout all runs\n",
    "        model = create_convnext_like_model(train_X.shape[1], test_y.shape[1])\n",
    "\n",
    "        print(f\"Run {run + 1}/{num_runs} started...\")\n",
    "        history = model.fit(\n",
    "            train_X, train_y, \n",
    "            epochs=100, \n",
    "            batch_size=int(train_X.shape[0] * 0.01),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=verbose_run\n",
    "        )\n",
    "        verbose_run = 0 # Suppress detailed output for multiple runs\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
    "        y_pred = model.predict(test_X, verbose=0)\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_true_classes = test_y.argmax(axis=1)\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        # Compute metrics\n",
    "        balanced_acc = balanced_accuracy_score(y_true_classes, y_pred_classes)\n",
    "        roc_auc = roc_auc_score(test_y, y_pred, multi_class='ovr')  # `test_y` is fine here for AUC\n",
    "        pr_auc = average_precision_score(test_y, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n",
    "        mcc = matthews_corrcoef(y_true_classes, y_pred_classes)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_storage['test_loss'].append(test_loss)\n",
    "        metrics_storage['test_accuracy'].append(test_acc)\n",
    "        metrics_storage['balanced_accuracy'].append(balanced_acc)\n",
    "        metrics_storage['roc_auc'].append(roc_auc)\n",
    "        metrics_storage['pr_auc'].append(pr_auc)\n",
    "        metrics_storage['f2'].append(f2)\n",
    "        metrics_storage['mcc'].append(mcc)\n",
    "\n",
    "        # Store classification report metrics\n",
    "        report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "        for label, values in report.items():\n",
    "            # Check if the value is a dictionary (e.g., 'precision', 'recall', 'f1-score')\n",
    "            if isinstance(values, dict):\n",
    "                for metric, value in values.items():\n",
    "                    metrics_storage[f\"{label}_{metric}\"].append(value)\n",
    "            else:\n",
    "                # Handle scalar values (like 'accuracy')\n",
    "                metrics_storage[label].append(values)\n",
    "\n",
    "        # Average the metrics over all successful runs\n",
    "        print(f\"\\nAggregated Metrics for {run+1} runs:\")\n",
    "        for metric, values in metrics_storage.items():\n",
    "            avg_value = np.mean(values)\n",
    "            print(f\"{metric}: {avg_value:.4f}\")\n",
    "\n",
    "    gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 789.51 MB\n",
      "Memory usage after optimization is: 196.60 MB\n",
      "Decreased by 75.1%\n",
      "Memory usage of dataframe is 197.38 MB\n",
      "Memory usage after optimization is: 49.15 MB\n",
      "Decreased by 75.1%\n",
      "Verbose output only for first run...\n",
      "Run 1/50 started...\n",
      "Epoch 1/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2007s\u001b[0m 20s/step - accuracy: 0.9316 - loss: 0.3859\n",
      "Epoch 2/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1985s\u001b[0m 20s/step - accuracy: 0.9976 - loss: 0.0102\n",
      "Epoch 3/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1984s\u001b[0m 20s/step - accuracy: 0.9983 - loss: 0.0071\n",
      "Epoch 4/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1987s\u001b[0m 20s/step - accuracy: 0.9984 - loss: 0.0066\n",
      "Epoch 5/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2002s\u001b[0m 20s/step - accuracy: 0.9986 - loss: 0.0055\n",
      "Epoch 6/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1991s\u001b[0m 20s/step - accuracy: 0.9983 - loss: 0.0068\n",
      "Epoch 7/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1994s\u001b[0m 20s/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 8/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1998s\u001b[0m 20s/step - accuracy: 0.9990 - loss: 0.0040\n",
      "Epoch 9/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1990s\u001b[0m 20s/step - accuracy: 0.9988 - loss: 0.0046\n",
      "Epoch 10/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1999s\u001b[0m 20s/step - accuracy: 0.9991 - loss: 0.0035\n",
      "Epoch 11/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1986s\u001b[0m 20s/step - accuracy: 0.9991 - loss: 0.0034\n",
      "Epoch 12/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1984s\u001b[0m 20s/step - accuracy: 0.9991 - loss: 0.0034\n",
      "Epoch 13/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2002s\u001b[0m 20s/step - accuracy: 0.9966 - loss: 0.0205\n",
      "Epoch 14/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1964s\u001b[0m 19s/step - accuracy: 0.9988 - loss: 0.0048\n",
      "Epoch 15/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1958s\u001b[0m 19s/step - accuracy: 0.9985 - loss: 0.0089\n",
      "Epoch 16/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1968s\u001b[0m 19s/step - accuracy: 0.9983 - loss: 0.0071\n",
      "Epoch 17/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1960s\u001b[0m 19s/step - accuracy: 0.9991 - loss: 0.0036\n",
      "Epoch 18/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1958s\u001b[0m 19s/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 19/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1960s\u001b[0m 19s/step - accuracy: 0.9974 - loss: 0.0111\n",
      "Epoch 20/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 20s/step - accuracy: 0.9966 - loss: 0.0177\n",
      "Epoch 21/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1965s\u001b[0m 19s/step - accuracy: 0.9988 - loss: 0.0047\n",
      "Epoch 22/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 19s/step - accuracy: 0.9990 - loss: 0.0040\n",
      "Epoch 23/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1966s\u001b[0m 19s/step - accuracy: 0.9992 - loss: 0.0031\n",
      "Epoch 24/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1974s\u001b[0m 20s/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 25/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1964s\u001b[0m 19s/step - accuracy: 0.9992 - loss: 0.0034\n",
      "Epoch 26/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 19s/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 27/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1963s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 28/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1971s\u001b[0m 20s/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 29/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1970s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 30/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1969s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 31/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1965s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 32/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1968s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 33/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1966s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 34/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1976s\u001b[0m 20s/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 35/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1988s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 36/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1967s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 37/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1970s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 38/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 19s/step - accuracy: 0.9992 - loss: 0.0028\n",
      "Epoch 39/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1972s\u001b[0m 20s/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 40/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1969s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 41/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1963s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 42/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 43/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1989s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0019\n",
      "Epoch 44/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1969s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 45/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1969s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 46/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1965s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 47/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1966s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 48/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2025s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 49/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2094s\u001b[0m 21s/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 50/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2068s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0021\n",
      "Epoch 51/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2051s\u001b[0m 20s/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 52/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2025s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0015\n",
      "Epoch 53/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 20s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 54/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2078s\u001b[0m 21s/step - accuracy: 0.9996 - loss: 0.0013\n",
      "Epoch 55/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2025s\u001b[0m 20s/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 56/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2028s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0020\n",
      "Epoch 57/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2006s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 58/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2043s\u001b[0m 20s/step - accuracy: 0.9994 - loss: 0.0018\n",
      "Epoch 59/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2033s\u001b[0m 20s/step - accuracy: 0.9996 - loss: 0.0013\n",
      "Epoch 60/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2099s\u001b[0m 21s/step - accuracy: 0.9995 - loss: 0.0014\n",
      "Epoch 61/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1978s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 62/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1961s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0014\n",
      "Epoch 63/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1968s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0012\n",
      "Epoch 64/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1960s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0014\n",
      "Epoch 65/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2022s\u001b[0m 20s/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 66/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2079s\u001b[0m 21s/step - accuracy: 0.9996 - loss: 0.0011\n",
      "Epoch 67/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2054s\u001b[0m 20s/step - accuracy: 0.9996 - loss: 0.0012\n",
      "Epoch 68/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2052s\u001b[0m 20s/step - accuracy: 0.9996 - loss: 0.0013\n",
      "Epoch 69/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1909s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0014\n",
      "Epoch 70/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1915s\u001b[0m 19s/step - accuracy: 0.9983 - loss: 0.0073\n",
      "Epoch 71/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1887s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 72/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1882s\u001b[0m 19s/step - accuracy: 0.9993 - loss: 0.0024\n",
      "Epoch 73/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1885s\u001b[0m 19s/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 74/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1893s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 75/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1895s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 76/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1886s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0015\n",
      "Epoch 77/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1898s\u001b[0m 19s/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 78/100\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1880s\u001b[0m 19s/step - accuracy: 0.9996 - loss: 0.0012\n",
      "\n",
      "Aggregated Metrics for 1 runs:\n",
      "test_loss: 0.0023\n",
      "test_accuracy: 0.9995\n",
      "balanced_accuracy: 0.8136\n",
      "roc_auc: 0.9998\n",
      "pr_auc: 0.9999\n",
      "f2: 0.9995\n",
      "mcc: 0.9942\n",
      "0_precision: 0.9996\n",
      "0_recall: 0.9999\n",
      "0_f1-score: 0.9998\n",
      "0_support: 194557.0000\n",
      "1_precision: 0.9987\n",
      "1_recall: 0.9943\n",
      "1_f1-score: 0.9965\n",
      "1_support: 3178.0000\n",
      "2_precision: 0.9936\n",
      "2_recall: 0.9912\n",
      "2_f1-score: 0.9924\n",
      "2_support: 2496.0000\n",
      "3_precision: 0.9995\n",
      "3_recall: 0.9981\n",
      "3_f1-score: 0.9988\n",
      "3_support: 2083.0000\n",
      "4_precision: 0.9978\n",
      "4_recall: 0.9611\n",
      "4_f1-score: 0.9791\n",
      "4_support: 463.0000\n",
      "5_precision: 1.0000\n",
      "5_recall: 0.9955\n",
      "5_f1-score: 0.9977\n",
      "5_support: 441.0000\n",
      "6_precision: 0.9641\n",
      "6_recall: 0.9216\n",
      "6_f1-score: 0.9424\n",
      "6_support: 204.0000\n",
      "7_precision: 1.0000\n",
      "7_recall: 1.0000\n",
      "7_f1-score: 1.0000\n",
      "7_support: 196.0000\n",
      "8_precision: 1.0000\n",
      "8_recall: 0.9811\n",
      "8_f1-score: 0.9905\n",
      "8_support: 53.0000\n",
      "9_precision: 1.0000\n",
      "9_recall: 0.9091\n",
      "9_f1-score: 0.9524\n",
      "9_support: 11.0000\n",
      "10_precision: 1.0000\n",
      "10_recall: 0.8333\n",
      "10_f1-score: 0.9091\n",
      "10_support: 6.0000\n",
      "11_precision: 1.0000\n",
      "11_recall: 0.7500\n",
      "11_f1-score: 0.8571\n",
      "11_support: 4.0000\n",
      "12_precision: 1.0000\n",
      "12_recall: 0.7500\n",
      "12_f1-score: 0.8571\n",
      "12_support: 4.0000\n",
      "13_precision: 1.0000\n",
      "13_recall: 0.5000\n",
      "13_f1-score: 0.6667\n",
      "13_support: 2.0000\n",
      "14_precision: 0.0000\n",
      "14_recall: 0.0000\n",
      "14_f1-score: 0.0000\n",
      "14_support: 2.0000\n",
      "15_precision: 1.0000\n",
      "15_recall: 1.0000\n",
      "15_f1-score: 1.0000\n",
      "15_support: 2.0000\n",
      "16_precision: 1.0000\n",
      "16_recall: 1.0000\n",
      "16_f1-score: 1.0000\n",
      "16_support: 1.0000\n",
      "17_precision: 1.0000\n",
      "17_recall: 0.5000\n",
      "17_f1-score: 0.6667\n",
      "17_support: 2.0000\n",
      "18_precision: 0.0000\n",
      "18_recall: 0.0000\n",
      "18_f1-score: 0.0000\n",
      "18_support: 1.0000\n",
      "19_precision: 1.0000\n",
      "19_recall: 1.0000\n",
      "19_f1-score: 1.0000\n",
      "19_support: 1.0000\n",
      "20_precision: 1.0000\n",
      "20_recall: 1.0000\n",
      "20_f1-score: 1.0000\n",
      "20_support: 1.0000\n",
      "accuracy: 0.9995\n",
      "macro avg_precision: 0.9025\n",
      "macro avg_recall: 0.8136\n",
      "macro avg_f1-score: 0.8479\n",
      "macro avg_support: 203708.0000\n",
      "weighted avg_precision: 0.9995\n",
      "weighted avg_recall: 0.9995\n",
      "weighted avg_f1-score: 0.9995\n",
      "weighted avg_support: 203708.0000\n",
      "Run 2/50 started...\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'normal.': 0, 'satan.': 1, 'ipsweep.': 2, 'portsweep.': 3, 'nmap.': 4,\n",
    "    'back.': 5, 'warezclient.': 6, 'teardrop.': 7, 'pod.': 8, 'guess_passwd.': 9,\n",
    "    'buffer_overflow.': 10, 'land.': 11, 'warezmaster.': 12, 'imap.': 13, 'rootkit.': 14,\n",
    "    'loadmodule.': 15, 'multihop.': 16, 'ftp_write.': 17, 'phf.': 18, 'perl.': 19, 'spy.': 20\n",
    "}\n",
    "\n",
    "run_model(\"kdd_train.csv\", \"kdd_test.csv\", is_string_labels = True, label_mapping=labels_map)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6246813,
     "sourceId": 10123278,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 142.560394,
   "end_time": "2024-12-17T09:25:46.512812",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-17T09:23:23.952418",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
