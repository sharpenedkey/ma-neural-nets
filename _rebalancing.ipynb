{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(labels):\n",
    "    \"\"\"\n",
    "    Calculate class weights for imbalanced datasets.\n",
    "    Args:\n",
    "        labels (np.array or list): The class labels in the dataset.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each class to its weight.\n",
    "    \"\"\"\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    return dict(zip(classes, weights))\n",
    "\n",
    "\n",
    "def apply_smote(X, y):\n",
    "    \"\"\"\n",
    "    Apply SMOTE to rebalance the dataset.\n",
    "    Args:\n",
    "        X (array-like): Features.\n",
    "        y (array-like): Labels.\n",
    "    Returns:\n",
    "        tuple: Rebalanced X and y.\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def apply_smote_dynamic(X, y):\n",
    "    \"\"\"\n",
    "    Apply SMOTE dynamically adjusting n_neighbors for smallest classes.\n",
    "    \"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    min_class_size = min(class_counts.values())\n",
    "    n_neighbors = min(5, min_class_size - 1)  # Adjust neighbors to fit smallest class\n",
    "    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def preprocess_largest_class(X, y):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by reducing the size of the largest class based on its\n",
    "    relative size to the second largest class.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Reduced X and y.\n",
    "    \"\"\"\n",
    "    # Count class frequencies\n",
    "    class_counts = Counter(y)\n",
    "    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    largest_class, largest_count = sorted_classes[0]\n",
    "    second_largest_count = sorted_classes[1][1]\n",
    "    \n",
    "    # Determine the target size for the largest class\n",
    "    if largest_count > 2 * second_largest_count:\n",
    "        target_size = largest_count // 2\n",
    "    else:\n",
    "        target_size = second_largest_count\n",
    "    \n",
    "    # Split the largest class\n",
    "    X_largest = X[y == largest_class]\n",
    "    y_largest = y[y == largest_class]\n",
    "    \n",
    "    # Resample the largest class to the target size\n",
    "    X_largest_reduced, y_largest_reduced = resample(\n",
    "        X_largest, y_largest, replace=False, n_samples=target_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Combine reduced largest class with the rest\n",
    "    X_rest = X[y != largest_class]\n",
    "    y_rest = y[y != largest_class]\n",
    "    X_final = pd.concat([X_rest, X_largest_reduced])\n",
    "    y_final = pd.concat([y_rest, y_largest_reduced])\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "\n",
    "def apply_smote_dynamic_with_reduction(X, y):\n",
    "    \"\"\"\n",
    "    Apply preprocessing to reduce the largest class, then apply SMOTE dynamically\n",
    "    with adjusted `n_neighbors` for smallest classes.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Resampled X and y.\n",
    "    \"\"\"\n",
    "    # Preprocess largest class\n",
    "    X, y = preprocess_largest_class(X, y)\n",
    "    \n",
    "    # Dynamically determine n_neighbors based on smallest class\n",
    "    class_counts = Counter(y)\n",
    "    min_class_size = min(class_counts.values())\n",
    "    n_neighbors = min(5, min_class_size - 1)  # Adjust neighbors to fit smallest class\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def downsample_largest_class(X, y):\n",
    "    \"\"\"\n",
    "    Downsample the largest class to the size of the second largest class.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Downsampled X and y.\n",
    "    \"\"\"\n",
    "    # Count class frequencies\n",
    "    class_counts = Counter(y)\n",
    "    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    largest_class, largest_count = sorted_classes[0]\n",
    "    second_largest_count = sorted_classes[1][1]\n",
    "    \n",
    "    # Resample the largest class to the size of the second largest\n",
    "    X_largest = X[y == largest_class]\n",
    "    y_largest = y[y == largest_class]\n",
    "    \n",
    "    X_largest_downsampled, y_largest_downsampled = resample(\n",
    "        X_largest, y_largest, replace=False, n_samples=second_largest_count, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Combine the downsampled largest class with the rest\n",
    "    X_rest = X[y != largest_class]\n",
    "    y_rest = y[y != largest_class]\n",
    "    X_final = pd.concat([X_rest, X_largest_downsampled])\n",
    "    y_final = pd.concat([y_rest, y_largest_downsampled])\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "\n",
    "def apply_smote_after_downsampling(X, y):\n",
    "    \"\"\"\n",
    "    Downsample the largest class to the size of the second largest class,\n",
    "    then apply SMOTE dynamically based on the smallest class size.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Resampled X and y.\n",
    "    \"\"\"\n",
    "    # Downsample the largest class\n",
    "    X, y = downsample_largest_class(X, y)\n",
    "    \n",
    "    # Determine n_neighbors dynamically based on the smallest class size\n",
    "    class_counts = Counter(y)\n",
    "    min_class_size = min(class_counts.values())\n",
    "    n_neighbors = min(5, min_class_size - 1)  # Adjust neighbors to fit smallest class\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svmsmote_with_limit(X, y, scaling_factor=5000, max_class_limit_ratio=1):\n",
    "    \"\"\"\n",
    "    Apply SVMSMOTE with a limit on how much minority classes can be upsampled.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Features of the dataset.\n",
    "        y (pd.Series): Labels of the dataset.\n",
    "        scaling_factor (int): Maximum upscaling factor for minority classes relative to their original size.\n",
    "        max_class_limit_ratio (float): Maximum oversampling limit as a fraction of the largest class size.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Resampled X and y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert y to a pandas Series for easier manipulation\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    # Dynamically determine n_neighbors based on smallest class\n",
    "    class_counts = Counter(y)\n",
    "    min_class_size = min(class_counts.values())\n",
    "    largest_class_size = max(class_counts.values())\n",
    "    n_neighbors = min(5, min_class_size - 1)  # Adjust neighbors to fit smallest class\n",
    "    j_neighbors = min(5, min_class_size - 1)\n",
    "\n",
    "    # Calculate target sizes for minority classes\n",
    "    smote_target_sizes = {\n",
    "        class_label: min(\n",
    "            scaling_factor * original_size,\n",
    "            int(largest_class_size * max_class_limit_ratio)\n",
    "        )\n",
    "        for class_label, original_size in class_counts.items()\n",
    "    }\n",
    "\n",
    "    # Adjust SVMSMOTE strategy to limit the oversampling\n",
    "    smote_strategy = {\n",
    "        class_label: target_size\n",
    "        for class_label, target_size in smote_target_sizes.items()\n",
    "        if target_size > class_counts[class_label]\n",
    "    }\n",
    "\n",
    "    # Apply SVMSMOTE with the limited strategy\n",
    "    smote = SVMSMOTE(sampling_strategy=smote_strategy, random_state=42, k_neighbors=n_neighbors, m_neighbors=j_neighbors)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    return pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "label\n",
      "normal.             778224\n",
      "satan.               12714\n",
      "ipsweep.              9985\n",
      "portsweep.            8330\n",
      "nmap.                 1853\n",
      "back.                 1762\n",
      "warezclient.           816\n",
      "teardrop.              783\n",
      "pod.                   211\n",
      "guess_passwd.           42\n",
      "buffer_overflow.        24\n",
      "land.                   17\n",
      "warezmaster.            16\n",
      "imap.                   10\n",
      "rootkit.                 8\n",
      "loadmodule.              7\n",
      "multihop.                6\n",
      "ftp_write.               6\n",
      "phf.                     2\n",
      "perl.                    2\n",
      "spy.                     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset (replace with your dataset path)\n",
    "dataset_path = \"shuttle_train.csv\"  # Example for KDD dataset\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Assume the last column is the target\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original Class Distribution:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebalance with SMOTE\n",
    "X_resampled, y_resampled = apply_svmsmote_with_limit(X, y)\n",
    "\n",
    "# Print resampled class distribution\n",
    "print(\"\\nResampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Visualize original and resampled distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "y.value_counts().sort_index().plot(kind='bar', ax=ax[0], title=\"Original Distribution\")\n",
    "pd.Series(y_resampled).value_counts().sort_index().plot(kind='bar', ax=ax[1], title=\"Resampled Distribution\")\n",
    "ax[0].set_xlabel(\"Class\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xlabel(\"Class\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optionally calculate class weights\n",
    "class_weights = calculate_class_weights(y_resampled)\n",
    "print(\"\\nClass Weights (After Resampling):\")\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "label\n",
      "normal.             778224\n",
      "satan.               12714\n",
      "ipsweep.              9985\n",
      "portsweep.            8330\n",
      "nmap.                 1853\n",
      "back.                 1762\n",
      "warezclient.           816\n",
      "teardrop.              783\n",
      "pod.                   211\n",
      "guess_passwd.           42\n",
      "buffer_overflow.        24\n",
      "land.                   17\n",
      "warezmaster.            16\n",
      "imap.                   10\n",
      "rootkit.                 8\n",
      "loadmodule.              7\n",
      "multihop.                6\n",
      "ftp_write.               6\n",
      "phf.                     2\n",
      "perl.                    2\n",
      "spy.                     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled Class Distribution:\n",
      "label\n",
      "satan.              12714\n",
      "guess_passwd.       12714\n",
      "spy.                12714\n",
      "perl.               12714\n",
      "ftp_write.          12714\n",
      "imap.               12714\n",
      "land.               12714\n",
      "multihop.           12714\n",
      "phf.                12714\n",
      "loadmodule.         12714\n",
      "warezmaster.        12714\n",
      "portsweep.          12714\n",
      "rootkit.            12714\n",
      "buffer_overflow.    12714\n",
      "warezclient.        12714\n",
      "teardrop.           12714\n",
      "back.               12714\n",
      "nmap.               12714\n",
      "ipsweep.            12714\n",
      "pod.                12714\n",
      "normal.             12714\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = \"kdd_train.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Apply the function\n",
    "X_resampled, y_resampled = apply_smote_after_downsampling(X, y)\n",
    "\n",
    "# Print original and resampled class distributions\n",
    "print(\"Original Class Distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "print(\"\\nResampled Class Distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
