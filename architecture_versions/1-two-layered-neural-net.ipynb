{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score, average_precision_score, fbeta_score, matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to build hidden combination (i.e. convolution) layers\n",
    "\n",
    "def create_random_combination_layer(input_layer, combination_size, num_combinations, input_dim):\n",
    "    outputs = []\n",
    "    \n",
    "    for _ in range(num_combinations):\n",
    "        # First random feature selection\n",
    "        indices_1 = np.random.choice(input_dim, combination_size, replace=False)\n",
    "        indices_tensor_1 = tf.constant(indices_1, dtype=tf.int32)\n",
    "        \n",
    "        # First feature selection using Lambda layer\n",
    "        slice_layer_1 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_1, axis=1),  # Gather selected features\n",
    "            output_shape=(combination_size,)\n",
    "        )(input_layer)\n",
    "        \n",
    "        # Second random feature selection (after the first random selection)\n",
    "        indices_2 = np.random.choice(combination_size, combination_size, replace=False)\n",
    "        indices_tensor_2 = tf.constant(indices_2, dtype=tf.int32)\n",
    "        \n",
    "        # Second feature selection using Lambda layer\n",
    "        slice_layer_2 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_2, axis=1),  # Apply a second feature selection\n",
    "            output_shape=(combination_size,)\n",
    "        )(slice_layer_1)\n",
    "\n",
    "        # Apply Dense layers on the final selected subset\n",
    "        selected_features = Dense(16, activation='relu')(\n",
    "            Dense(8, activation='relu')(\n",
    "                Dense(4, activation='relu')(slice_layer_2)\n",
    "            )\n",
    "        )\n",
    "        outputs.append(selected_features)\n",
    "    \n",
    "    # Concatenate the outputs from all the random feature combinations\n",
    "    return Concatenate()(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train_data_path, test_data_path, is_string_labels = False, label_mapping = None):\n",
    "\n",
    "    # Initialize the one-hot encoder for the target\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Load and Prepare Training Data\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        train_data['label'] = train_data['label'].map(label_mapping)\n",
    "    train_X = train_data.drop(columns=['label']).values\n",
    "    train_y = train_data['label'].values\n",
    "    train_y = encoder.fit_transform(train_y.reshape(-1, 1))\n",
    "\n",
    "    # Perform a stratified split into train and validation sets (80% train, 20% validation)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)\n",
    "\n",
    "    # Load and Prepare Test Data (this will not be used in training)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    test_data = test_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        test_data['label'] = test_data['label'].map(label_mapping)\n",
    "    test_X = test_data.drop(columns=['label']).values\n",
    "    test_y = test_data['label'].values\n",
    "    test_y = encoder.transform(test_y.reshape(-1, 1))\n",
    "\n",
    "    # Parameters for Random Feature Combination\n",
    "    num_combinations = 20  # Number of random column combinations\n",
    "    combination_size = 3   # Number of columns in each combination\n",
    "\n",
    "    # Number of features and classes of the original dataset\n",
    "    num_features = train_X.shape[1]\n",
    "    num_classes = train_y.shape[1]\n",
    "\n",
    "    # EarlyStopping Callback (optional, to avoid overfitting)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Number of runs for averaging results\n",
    "    num_runs = 5\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    metrics_storage = defaultdict(list)\n",
    "\n",
    "    # Train the Model with Validation Split N tines for more accurate metrics\n",
    "    print(\"Verbose output only for first run...\")\n",
    "    verbose_run = 1\n",
    "    for run in range(num_runs):\n",
    "        \n",
    "        # Model is defined separately in each run, since the random combination layers\n",
    "        # must be randomly initialized each time. Otherwise, the \"random\" indices stay the same\n",
    "        # throughout all runs\n",
    "        input_layer = Input(shape=(X_train.shape[1],))  # Input shape from the training data\n",
    "        feature_layer = create_random_combination_layer(input_layer, combination_size, num_combinations, X_train.shape[1])\n",
    "        hidden_layer = Dense(128, activation='relu')(feature_layer)\n",
    "        hidden_layer = Dropout(0.5)(hidden_layer)\n",
    "        output_layer = Dense(test_y.shape[1], activation='softmax')(hidden_layer)\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(f\"Run {run + 1}/{num_runs} started...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            epochs=1000, \n",
    "            batch_size=32, \n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=verbose_run\n",
    "        )\n",
    "        verbose_run = 0 # Suppress detailed output for multiple runs\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
    "        y_pred = model.predict(test_X, verbose=0)\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_true_classes = test_y.argmax(axis=1)\n",
    "\n",
    "        # Compute metrics\n",
    "        balanced_acc = balanced_accuracy_score(test_y, y_pred)\n",
    "        roc_auc = roc_auc_score(test_y, y_pred, multi_class='ovr')\n",
    "        pr_auc = average_precision_score(test_y, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n",
    "        mcc = matthews_corrcoef(y_true_classes, y_pred_classes)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_storage['test_loss'].append(test_loss)\n",
    "        metrics_storage['test_accuracy'].append(test_acc)\n",
    "        metrics_storage['balanced_accuracy'].append(balanced_acc)\n",
    "        metrics_storage['roc_auc'].append(roc_auc)\n",
    "        metrics_storage['pr_auc'].append(pr_auc)\n",
    "        metrics_storage['f2'].append(f2)\n",
    "        metrics_storage['mcc'].append(mcc)\n",
    "\n",
    "        # Store classification report metrics\n",
    "        report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "        for label, values in report.items():\n",
    "            # Check if the value is a dictionary (e.g., 'precision', 'recall', 'f1-score')\n",
    "            if isinstance(values, dict):\n",
    "                for metric, value in values.items():\n",
    "                    metrics_storage[f\"{label}_{metric}\"].append(value)\n",
    "            else:\n",
    "                # Handle scalar values (like 'accuracy')\n",
    "                metrics_storage[label].append(values)\n",
    "\n",
    "    # Average the metrics over all runs\n",
    "    print(\"\\nAggregated Metrics:\")\n",
    "    for metric, values in metrics_storage.items():\n",
    "        avg_value = np.mean(values)\n",
    "        print(f\"{metric}: {avg_value:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9338 - loss: 0.3094 - val_accuracy: 0.9945 - val_loss: 0.0324\n",
      "Epoch 2/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0283 - val_accuracy: 0.9982 - val_loss: 0.0126\n",
      "Epoch 3/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0174 - val_accuracy: 0.9981 - val_loss: 0.0131\n",
      "Epoch 4/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0180 - val_accuracy: 0.9981 - val_loss: 0.0061\n",
      "Epoch 5/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0102 - val_accuracy: 0.9988 - val_loss: 0.0057\n",
      "Epoch 6/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.9982 - val_loss: 0.0048\n",
      "Epoch 7/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9991 - val_loss: 0.0055\n",
      "Epoch 8/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9990 - val_loss: 0.0047\n",
      "Epoch 9/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9991 - val_loss: 0.0052\n",
      "Epoch 10/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9982 - val_loss: 0.0051\n",
      "Epoch 11/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 12/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0029 - val_accuracy: 0.9989 - val_loss: 0.0046\n",
      "Epoch 13/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9991 - val_loss: 0.0045\n",
      "Epoch 14/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 15/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9994 - val_loss: 0.0042\n",
      "Epoch 16/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9994 - val_loss: 0.0034\n",
      "Epoch 17/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9995 - val_loss: 0.0042\n",
      "Epoch 18/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9992 - val_loss: 0.0047\n",
      "Epoch 19/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9987 - val_loss: 0.0050\n",
      "Epoch 20/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9990 - val_loss: 0.0043\n",
      "Epoch 21/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9986 - val_loss: 0.0048\n",
      "Epoch 22/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9989 - val_loss: 0.0029\n",
      "Epoch 23/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 0.9992 - val_loss: 0.0028\n",
      "Epoch 24/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
      "Epoch 25/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9987 - val_loss: 0.0044\n",
      "Epoch 26/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9991 - val_loss: 0.0031\n",
      "Epoch 27/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9995 - val_loss: 0.0040\n",
      "Epoch 28/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0074 - val_accuracy: 0.9996 - val_loss: 0.0029\n",
      "Epoch 29/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
      "Epoch 30/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9994 - val_loss: 0.0034\n",
      "Epoch 31/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.9994 - val_loss: 0.0030\n",
      "Epoch 32/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
      "Epoch 33/1000\n",
      "\u001b[1m1160/1160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9994 - val_loss: 0.0033\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.0886\n",
      "test_accuracy: 0.9699\n",
      "roc_auc: 0.9016\n",
      "pr_auc: 0.9828\n",
      "f2: 0.9694\n",
      "mcc: 0.9170\n",
      "0_precision: 0.9857\n",
      "0_recall: 0.9796\n",
      "0_f1-score: 0.9826\n",
      "0_support: 9117.0000\n",
      "1_precision: 0.2000\n",
      "1_recall: 0.2000\n",
      "1_f1-score: 0.2000\n",
      "1_support: 10.0000\n",
      "2_precision: 0.5833\n",
      "2_recall: 0.2471\n",
      "2_f1-score: 0.2810\n",
      "2_support: 34.0000\n",
      "3_precision: 0.8980\n",
      "3_recall: 0.9331\n",
      "3_f1-score: 0.9143\n",
      "3_support: 1781.0000\n",
      "4_precision: 0.9673\n",
      "4_recall: 0.9908\n",
      "4_f1-score: 0.9787\n",
      "4_support: 653.0000\n",
      "5_precision: 0.2000\n",
      "5_recall: 0.1000\n",
      "5_f1-score: 0.1333\n",
      "5_support: 2.0000\n",
      "6_precision: 0.1457\n",
      "6_recall: 0.4000\n",
      "6_f1-score: 0.2123\n",
      "6_support: 3.0000\n",
      "accuracy: 0.9699\n",
      "macro avg_precision: 0.5686\n",
      "macro avg_recall: 0.5501\n",
      "macro avg_f1-score: 0.5289\n",
      "macro avg_support: 11600.0000\n",
      "weighted avg_precision: 0.9690\n",
      "weighted avg_recall: 0.9699\n",
      "weighted avg_f1-score: 0.9688\n",
      "weighted avg_support: 11600.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"shuttle_train.csv\", \"shuttle_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - accuracy: 0.5079 - loss: 1.1991 - val_accuracy: 0.5130 - val_loss: 1.1757\n",
      "Epoch 2/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5122 - loss: 1.1787 - val_accuracy: 0.5130 - val_loss: 1.1734\n",
      "Epoch 3/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5126 - loss: 1.1770 - val_accuracy: 0.5130 - val_loss: 1.1725\n",
      "Epoch 4/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5139 - loss: 1.1748 - val_accuracy: 0.5130 - val_loss: 1.1727\n",
      "Epoch 5/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5132 - loss: 1.1735 - val_accuracy: 0.5130 - val_loss: 1.1725\n",
      "Epoch 6/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - accuracy: 0.5142 - loss: 1.1717 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 7/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5118 - loss: 1.1749 - val_accuracy: 0.5130 - val_loss: 1.1724\n",
      "Epoch 8/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5115 - loss: 1.1774 - val_accuracy: 0.5130 - val_loss: 1.1726\n",
      "Epoch 9/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5155 - loss: 1.1717 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 10/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5137 - loss: 1.1715 - val_accuracy: 0.5130 - val_loss: 1.1729\n",
      "Epoch 11/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5155 - loss: 1.1720 - val_accuracy: 0.5130 - val_loss: 1.1726\n",
      "Epoch 12/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5149 - loss: 1.1734 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 13/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5126 - loss: 1.1744 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 14/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 1.1757 - val_accuracy: 0.5130 - val_loss: 1.1730\n",
      "Epoch 15/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5123 - loss: 1.1739 - val_accuracy: 0.5130 - val_loss: 1.1722\n",
      "Epoch 16/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5126 - loss: 1.1740 - val_accuracy: 0.5130 - val_loss: 1.1729\n",
      "Epoch 17/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5139 - loss: 1.1727 - val_accuracy: 0.5130 - val_loss: 1.1721\n",
      "Epoch 18/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5127 - loss: 1.1735 - val_accuracy: 0.5130 - val_loss: 1.1721\n",
      "Epoch 19/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5144 - loss: 1.1737 - val_accuracy: 0.5130 - val_loss: 1.1721\n",
      "Epoch 20/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5143 - loss: 1.1723 - val_accuracy: 0.5130 - val_loss: 1.1726\n",
      "Epoch 21/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5134 - loss: 1.1753 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 22/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5133 - loss: 1.1746 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 23/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 1.1734 - val_accuracy: 0.5130 - val_loss: 1.1727\n",
      "Epoch 24/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5130 - loss: 1.1743 - val_accuracy: 0.5130 - val_loss: 1.1727\n",
      "Epoch 25/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5114 - loss: 1.1761 - val_accuracy: 0.5130 - val_loss: 1.1725\n",
      "Epoch 26/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5122 - loss: 1.1757 - val_accuracy: 0.5130 - val_loss: 1.1723\n",
      "Epoch 27/1000\n",
      "\u001b[1m11621/11621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.5128 - loss: 1.1728 - val_accuracy: 0.5130 - val_loss: 1.1721\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 1.0857\n",
      "test_accuracy: 0.5338\n",
      "roc_auc: 0.6417\n",
      "pr_auc: 0.4569\n",
      "f2: 0.4718\n",
      "mcc: 0.1506\n",
      "0_precision: 0.5068\n",
      "0_recall: 0.1827\n",
      "0_f1-score: 0.1977\n",
      "0_support: 42368.0000\n",
      "1_precision: 0.5390\n",
      "1_recall: 0.9347\n",
      "1_f1-score: 0.6725\n",
      "1_support: 56661.0000\n",
      "2_precision: 0.2370\n",
      "2_recall: 0.1386\n",
      "2_f1-score: 0.1396\n",
      "2_support: 7151.0000\n",
      "3_precision: 0.0000\n",
      "3_recall: 0.0000\n",
      "3_f1-score: 0.0000\n",
      "3_support: 549.0000\n",
      "4_precision: 0.0000\n",
      "4_recall: 0.0000\n",
      "4_f1-score: 0.0000\n",
      "4_support: 1899.0000\n",
      "5_precision: 0.0000\n",
      "5_recall: 0.0000\n",
      "5_f1-score: 0.0000\n",
      "5_support: 3473.0000\n",
      "6_precision: 0.4212\n",
      "6_recall: 0.0823\n",
      "6_f1-score: 0.1223\n",
      "6_support: 4102.0000\n",
      "accuracy: 0.5338\n",
      "macro avg_precision: 0.2434\n",
      "macro avg_recall: 0.1912\n",
      "macro avg_f1-score: 0.1617\n",
      "macro avg_support: 116203.0000\n",
      "weighted avg_precision: 0.4771\n",
      "weighted avg_recall: 0.5338\n",
      "weighted avg_f1-score: 0.4129\n",
      "weighted avg_support: 116203.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"covtype_train.csv\", \"covtype_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.2434 - val_accuracy: 0.9551 - val_loss: 0.2045\n",
      "Epoch 2/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.2058 - val_accuracy: 0.9551 - val_loss: 0.2042\n",
      "Epoch 3/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.2053 - val_accuracy: 0.9551 - val_loss: 0.2042\n",
      "Epoch 4/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.2030 - val_accuracy: 0.9551 - val_loss: 0.2047\n",
      "Epoch 5/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6ms/step - accuracy: 0.9551 - loss: 0.2036 - val_accuracy: 0.9551 - val_loss: 0.2045\n",
      "Epoch 6/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.2047 - val_accuracy: 0.9551 - val_loss: 0.2043\n",
      "Epoch 7/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.2035 - val_accuracy: 0.9551 - val_loss: 0.2042\n",
      "Epoch 8/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.2025 - val_accuracy: 0.9551 - val_loss: 0.2044\n",
      "Epoch 9/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.2049 - val_accuracy: 0.9551 - val_loss: 0.2041\n",
      "Epoch 10/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.2026 - val_accuracy: 0.9551 - val_loss: 0.2041\n",
      "Epoch 11/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.2042 - val_accuracy: 0.9551 - val_loss: 0.2044\n",
      "Epoch 12/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.2025 - val_accuracy: 0.9551 - val_loss: 0.2046\n",
      "Epoch 13/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.2046 - val_accuracy: 0.9551 - val_loss: 0.2045\n",
      "Epoch 14/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.2032 - val_accuracy: 0.9551 - val_loss: 0.2043\n",
      "Epoch 15/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.2024 - val_accuracy: 0.9551 - val_loss: 0.2045\n",
      "Epoch 16/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.2056 - val_accuracy: 0.9551 - val_loss: 0.2043\n",
      "Epoch 17/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9551 - loss: 0.2039 - val_accuracy: 0.9551 - val_loss: 0.2046\n",
      "Epoch 18/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.2041 - val_accuracy: 0.9551 - val_loss: 0.2043\n",
      "Epoch 19/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.2053 - val_accuracy: 0.9551 - val_loss: 0.2052\n",
      "Epoch 20/1000\n",
      "\u001b[1m20371/20371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.2037 - val_accuracy: 0.9551 - val_loss: 0.2045\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.1576\n",
      "test_accuracy: 0.9640\n",
      "roc_auc: 0.8034\n",
      "pr_auc: 0.9561\n",
      "f2: 0.9573\n",
      "mcc: 0.3463\n",
      "0_precision: 0.9658\n",
      "0_recall: 0.9996\n",
      "0_f1-score: 0.9824\n",
      "0_support: 194557.0000\n",
      "1_precision: 0.3256\n",
      "1_recall: 0.3482\n",
      "1_f1-score: 0.3343\n",
      "1_support: 3178.0000\n",
      "2_precision: 0.4756\n",
      "2_recall: 0.1928\n",
      "2_f1-score: 0.2061\n",
      "2_support: 2496.0000\n",
      "3_precision: 0.2995\n",
      "3_recall: 0.1502\n",
      "3_f1-score: 0.1586\n",
      "3_support: 2083.0000\n",
      "4_precision: 0.0000\n",
      "4_recall: 0.0000\n",
      "4_f1-score: 0.0000\n",
      "4_support: 463.0000\n",
      "5_precision: 0.0000\n",
      "5_recall: 0.0000\n",
      "5_f1-score: 0.0000\n",
      "5_support: 441.0000\n",
      "6_precision: 0.0000\n",
      "6_recall: 0.0000\n",
      "6_f1-score: 0.0000\n",
      "6_support: 204.0000\n",
      "7_precision: 0.0000\n",
      "7_recall: 0.0000\n",
      "7_f1-score: 0.0000\n",
      "7_support: 196.0000\n",
      "8_precision: 0.1297\n",
      "8_recall: 0.0906\n",
      "8_f1-score: 0.1067\n",
      "8_support: 53.0000\n",
      "9_precision: 0.0000\n",
      "9_recall: 0.0000\n",
      "9_f1-score: 0.0000\n",
      "9_support: 11.0000\n",
      "10_precision: 0.0000\n",
      "10_recall: 0.0000\n",
      "10_f1-score: 0.0000\n",
      "10_support: 6.0000\n",
      "11_precision: 0.0000\n",
      "11_recall: 0.0000\n",
      "11_f1-score: 0.0000\n",
      "11_support: 4.0000\n",
      "12_precision: 0.0000\n",
      "12_recall: 0.0000\n",
      "12_f1-score: 0.0000\n",
      "12_support: 4.0000\n",
      "13_precision: 0.0000\n",
      "13_recall: 0.0000\n",
      "13_f1-score: 0.0000\n",
      "13_support: 2.0000\n",
      "14_precision: 0.0000\n",
      "14_recall: 0.0000\n",
      "14_f1-score: 0.0000\n",
      "14_support: 2.0000\n",
      "15_precision: 0.0000\n",
      "15_recall: 0.0000\n",
      "15_f1-score: 0.0000\n",
      "15_support: 2.0000\n",
      "16_precision: 0.0000\n",
      "16_recall: 0.0000\n",
      "16_f1-score: 0.0000\n",
      "16_support: 1.0000\n",
      "17_precision: 0.0000\n",
      "17_recall: 0.0000\n",
      "17_f1-score: 0.0000\n",
      "17_support: 2.0000\n",
      "18_precision: 0.0000\n",
      "18_recall: 0.0000\n",
      "18_f1-score: 0.0000\n",
      "18_support: 1.0000\n",
      "19_precision: 0.0000\n",
      "19_recall: 0.0000\n",
      "19_f1-score: 0.0000\n",
      "19_support: 1.0000\n",
      "20_precision: 0.0000\n",
      "20_recall: 0.0000\n",
      "20_f1-score: 0.0000\n",
      "20_support: 1.0000\n",
      "accuracy: 0.9640\n",
      "macro avg_precision: 0.1046\n",
      "macro avg_recall: 0.0848\n",
      "macro avg_f1-score: 0.0851\n",
      "macro avg_support: 203708.0000\n",
      "weighted avg_precision: 0.9364\n",
      "weighted avg_recall: 0.9640\n",
      "weighted avg_f1-score: 0.9476\n",
      "weighted avg_support: 203708.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'normal.': 0, 'satan.': 1, 'ipsweep.': 2, 'portsweep.': 3, 'nmap.': 4,\n",
    "    'back.': 5, 'warezclient.': 6, 'teardrop.': 7, 'pod.': 8, 'guess_passwd.': 9,\n",
    "    'buffer_overflow.': 10, 'land.': 11, 'warezmaster.': 12, 'imap.': 13, 'rootkit.': 14,\n",
    "    'loadmodule.': 15, 'multihop.': 16, 'ftp_write.': 17, 'phf.': 18, 'perl.': 19, 'spy.': 20\n",
    "}\n",
    "\n",
    "run_model(\"kdd_train.csv\", \"kdd_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.6164 - val_accuracy: 0.8466 - val_loss: 0.4861\n",
      "Epoch 2/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8462 - loss: 0.4993 - val_accuracy: 0.8467 - val_loss: 0.4811\n",
      "Epoch 3/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8471 - loss: 0.4849 - val_accuracy: 0.8467 - val_loss: 0.4674\n",
      "Epoch 4/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.4817 - val_accuracy: 0.8467 - val_loss: 0.4624\n",
      "Epoch 5/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4666 - val_accuracy: 0.8468 - val_loss: 0.4631\n",
      "Epoch 6/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8475 - loss: 0.4655 - val_accuracy: 0.8467 - val_loss: 0.4721\n",
      "Epoch 7/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8475 - loss: 0.4617 - val_accuracy: 0.8467 - val_loss: 0.4578\n",
      "Epoch 8/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.4692 - val_accuracy: 0.8468 - val_loss: 0.4544\n",
      "Epoch 9/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8490 - loss: 0.4607 - val_accuracy: 0.8467 - val_loss: 0.4556\n",
      "Epoch 10/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 0.4567 - val_accuracy: 0.8466 - val_loss: 0.4553\n",
      "Epoch 11/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.4592 - val_accuracy: 0.8468 - val_loss: 0.4587\n",
      "Epoch 12/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8487 - loss: 0.4570 - val_accuracy: 0.8468 - val_loss: 0.4528\n",
      "Epoch 13/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8475 - loss: 0.4537 - val_accuracy: 0.8468 - val_loss: 0.4535\n",
      "Epoch 14/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.4606 - val_accuracy: 0.8468 - val_loss: 0.4618\n",
      "Epoch 15/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8474 - loss: 0.4541 - val_accuracy: 0.8468 - val_loss: 0.4584\n",
      "Epoch 16/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.4546 - val_accuracy: 0.8468 - val_loss: 0.4584\n",
      "Epoch 17/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.4623 - val_accuracy: 0.8468 - val_loss: 0.4536\n",
      "Epoch 18/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.4556 - val_accuracy: 0.8468 - val_loss: 0.4520\n",
      "Epoch 19/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.4552 - val_accuracy: 0.8468 - val_loss: 0.4549\n",
      "Epoch 20/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.4549 - val_accuracy: 0.8468 - val_loss: 0.4521\n",
      "Epoch 21/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 0.4532 - val_accuracy: 0.8469 - val_loss: 0.4506\n",
      "Epoch 22/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8451 - loss: 0.4596 - val_accuracy: 0.8470 - val_loss: 0.4517\n",
      "Epoch 23/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.4511 - val_accuracy: 0.8468 - val_loss: 0.4549\n",
      "Epoch 24/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8442 - loss: 0.4631 - val_accuracy: 0.8468 - val_loss: 0.4550\n",
      "Epoch 25/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8455 - loss: 0.4540 - val_accuracy: 0.8468 - val_loss: 0.4524\n",
      "Epoch 26/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8464 - loss: 0.4621 - val_accuracy: 0.8468 - val_loss: 0.4533\n",
      "Epoch 27/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.4579 - val_accuracy: 0.8466 - val_loss: 0.4503\n",
      "Epoch 28/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.4522 - val_accuracy: 0.8466 - val_loss: 0.4579\n",
      "Epoch 29/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.4498 - val_accuracy: 0.8469 - val_loss: 0.4504\n",
      "Epoch 30/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8474 - loss: 0.4506 - val_accuracy: 0.8468 - val_loss: 0.4565\n",
      "Epoch 31/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.4504 - val_accuracy: 0.8467 - val_loss: 0.4524\n",
      "Epoch 32/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8470 - loss: 0.4519 - val_accuracy: 0.8480 - val_loss: 0.4526\n",
      "Epoch 33/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.4531 - val_accuracy: 0.8469 - val_loss: 0.4510\n",
      "Epoch 34/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8462 - loss: 0.4535 - val_accuracy: 0.8479 - val_loss: 0.4547\n",
      "Epoch 35/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4539 - val_accuracy: 0.8480 - val_loss: 0.4513\n",
      "Epoch 36/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8466 - loss: 0.4513 - val_accuracy: 0.8479 - val_loss: 0.4732\n",
      "Epoch 37/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.4608 - val_accuracy: 0.8479 - val_loss: 0.4493\n",
      "Epoch 38/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.4512 - val_accuracy: 0.8468 - val_loss: 0.4583\n",
      "Epoch 39/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.4535 - val_accuracy: 0.8479 - val_loss: 0.5162\n",
      "Epoch 40/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.4506 - val_accuracy: 0.8478 - val_loss: 0.4498\n",
      "Epoch 41/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.4544 - val_accuracy: 0.8479 - val_loss: 0.4528\n",
      "Epoch 42/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8479 - loss: 0.4525 - val_accuracy: 0.8480 - val_loss: 0.4484\n",
      "Epoch 43/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.4552 - val_accuracy: 0.8470 - val_loss: 0.4503\n",
      "Epoch 44/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.4510 - val_accuracy: 0.8485 - val_loss: 0.4541\n",
      "Epoch 45/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.4518 - val_accuracy: 0.8478 - val_loss: 0.4531\n",
      "Epoch 46/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8462 - loss: 0.4550 - val_accuracy: 0.8487 - val_loss: 0.4505\n",
      "Epoch 47/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8471 - loss: 0.4522 - val_accuracy: 0.8478 - val_loss: 0.4521\n",
      "Epoch 48/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.4485 - val_accuracy: 0.8468 - val_loss: 0.4511\n",
      "Epoch 49/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.4494 - val_accuracy: 0.8467 - val_loss: 0.4511\n",
      "Epoch 50/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8456 - loss: 0.4552 - val_accuracy: 0.8466 - val_loss: 0.4564\n",
      "Epoch 51/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.4583 - val_accuracy: 0.8474 - val_loss: 0.4504\n",
      "Epoch 52/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8464 - loss: 0.4536 - val_accuracy: 0.8484 - val_loss: 0.4475\n",
      "Epoch 53/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.4481 - val_accuracy: 0.8480 - val_loss: 0.4492\n",
      "Epoch 54/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.4513 - val_accuracy: 0.8483 - val_loss: 0.4521\n",
      "Epoch 55/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.4523 - val_accuracy: 0.8466 - val_loss: 0.4494\n",
      "Epoch 56/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.4506 - val_accuracy: 0.8484 - val_loss: 0.4507\n",
      "Epoch 57/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.4490 - val_accuracy: 0.8466 - val_loss: 0.4513\n",
      "Epoch 58/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.4504 - val_accuracy: 0.8486 - val_loss: 0.4503\n",
      "Epoch 59/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8455 - loss: 0.4552 - val_accuracy: 0.8487 - val_loss: 0.4555\n",
      "Epoch 60/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.4551 - val_accuracy: 0.8479 - val_loss: 0.4553\n",
      "Epoch 61/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 0.4488 - val_accuracy: 0.8483 - val_loss: 0.4587\n",
      "Epoch 62/1000\n",
      "\u001b[1m3173/3173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.4458 - val_accuracy: 0.8484 - val_loss: 0.4527\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.4204\n",
      "test_accuracy: 0.8731\n",
      "roc_auc: 0.8556\n",
      "pr_auc: 0.8650\n",
      "f2: 0.8501\n",
      "mcc: 0.2384\n",
      "0_precision: 0.8774\n",
      "0_recall: 0.9970\n",
      "0_f1-score: 0.9325\n",
      "0_support: 26862.0000\n",
      "1_precision: 0.3060\n",
      "1_recall: 0.1973\n",
      "1_f1-score: 0.2074\n",
      "1_support: 2657.0000\n",
      "2_precision: 0.1954\n",
      "2_recall: 0.1976\n",
      "2_f1-score: 0.1965\n",
      "2_support: 908.0000\n",
      "3_precision: 0.1935\n",
      "3_recall: 0.1812\n",
      "3_f1-score: 0.1609\n",
      "3_support: 522.0000\n",
      "4_precision: 0.1550\n",
      "4_recall: 0.1809\n",
      "4_f1-score: 0.1669\n",
      "4_support: 293.0000\n",
      "5_precision: 0.2458\n",
      "5_recall: 0.1398\n",
      "5_f1-score: 0.1013\n",
      "5_support: 269.0000\n",
      "6_precision: 0.2000\n",
      "6_recall: 0.1983\n",
      "6_f1-score: 0.1991\n",
      "6_support: 116.0000\n",
      "7_precision: 0.0000\n",
      "7_recall: 0.0000\n",
      "7_f1-score: 0.0000\n",
      "7_support: 53.0000\n",
      "8_precision: 0.1765\n",
      "8_recall: 0.1364\n",
      "8_f1-score: 0.1538\n",
      "8_support: 44.0000\n",
      "accuracy: 0.8731\n",
      "macro avg_precision: 0.2611\n",
      "macro avg_recall: 0.2476\n",
      "macro avg_f1-score: 0.2354\n",
      "macro avg_support: 31724.0000\n",
      "weighted avg_precision: 0.7818\n",
      "weighted avg_recall: 0.8731\n",
      "weighted avg_f1-score: 0.8186\n",
      "weighted avg_support: 31724.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'Normal': 0, 'Darknet_Audio-Streaming': 1, 'Darknet_Chat': 2, 'Darknet_File-Transfer': 3, 'Darknet_VOIP': 4,\n",
    "    'Darknet_Video-Streaming': 5, 'Darknet_Email': 6, 'Darknet_Browsing': 7, 'Darknet_P2P': 8\n",
    "}\n",
    "\n",
    "run_model(\"darknet_train.csv\", \"darknet_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
