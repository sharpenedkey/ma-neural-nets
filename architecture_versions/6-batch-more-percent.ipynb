{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score, average_precision_score, fbeta_score, matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to build hidden combination (i.e. convolution) layers\n",
    "\n",
    "def create_random_combination_layer(input_layer, combination_size, num_combinations, input_dim):\n",
    "    outputs = []\n",
    "    \n",
    "    for _ in range(num_combinations):\n",
    "        # First random feature selection\n",
    "        indices_1 = np.random.choice(input_dim, combination_size, replace=False)\n",
    "        indices_tensor_1 = tf.constant(indices_1, dtype=tf.int32)\n",
    "        \n",
    "        # First feature selection using Lambda layer\n",
    "        slice_layer_1 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_1, axis=1),  # Gather selected features\n",
    "            output_shape=(combination_size,)\n",
    "        )(input_layer)\n",
    "        \n",
    "        # Second random feature selection (after the first random selection)\n",
    "        indices_2 = np.random.choice(combination_size, combination_size, replace=False)\n",
    "        indices_tensor_2 = tf.constant(indices_2, dtype=tf.int32)\n",
    "        \n",
    "        # Second feature selection using Lambda layer\n",
    "        slice_layer_2 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_2, axis=1),  # Apply a second feature selection\n",
    "            output_shape=(combination_size,)\n",
    "        )(slice_layer_1)\n",
    "\n",
    "        # Apply Dense layers on the final selected subset\n",
    "        selected_features = Dense(16, activation='relu')(\n",
    "            Dense(8, activation='relu')(\n",
    "                Dense(4, activation='relu')(slice_layer_2)\n",
    "            )\n",
    "        )\n",
    "        outputs.append(selected_features)\n",
    "    \n",
    "    # Concatenate the outputs from all the random feature combinations\n",
    "    return Concatenate()(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train_data_path, test_data_path, is_string_labels = False, label_mapping = None):\n",
    "\n",
    "    # Initialize the one-hot encoder for the target\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Load and Prepare Training Data\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        train_data['label'] = train_data['label'].map(label_mapping)\n",
    "    train_X = train_data.drop(columns=['label']).values\n",
    "    train_y = train_data['label'].values\n",
    "    train_y = encoder.fit_transform(train_y.reshape(-1, 1))\n",
    "\n",
    "    # Perform a stratified split into train and validation sets (80% train, 20% validation)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)\n",
    "\n",
    "    # Load and Prepare Test Data (this will not be used in training)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    test_data = test_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        test_data['label'] = test_data['label'].map(label_mapping)\n",
    "    test_X = test_data.drop(columns=['label']).values\n",
    "    test_y = test_data['label'].values\n",
    "    test_y = encoder.transform(test_y.reshape(-1, 1))\n",
    "\n",
    "    # Parameters for Random Feature Combination\n",
    "    num_combinations = 20  # Number of random column combinations\n",
    "    combination_size = 3   # Number of columns in each combination\n",
    "\n",
    "    # Number of features and classes of the original dataset\n",
    "    num_features = train_X.shape[1]\n",
    "    num_classes = train_y.shape[1]\n",
    "\n",
    "    # EarlyStopping Callback (optional, to avoid overfitting)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Number of runs for averaging results\n",
    "    num_runs = 5\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    metrics_storage = defaultdict(list)\n",
    "\n",
    "    # Train the Model with Validation Split N tines for more accurate metrics\n",
    "    print(\"Verbose output only for first run...\")\n",
    "    verbose_run = 1\n",
    "    for run in range(num_runs):\n",
    "        \n",
    "        # Model is defined separately in each run, since the random combination layers\n",
    "        # must be randomly initialized each time. Otherwise, the \"random\" indices stay the same\n",
    "        # throughout all runs\n",
    "        input_layer = Input(shape=(X_train.shape[1],))  # Input shape from the training data\n",
    "        feature_layer = create_random_combination_layer(input_layer, combination_size, num_combinations, X_train.shape[1])\n",
    "        hidden_layer = Dense(128, activation='relu')(feature_layer)\n",
    "        hidden_layer = Dropout(0.5)(hidden_layer)\n",
    "        output_layer = Dense(test_y.shape[1], activation='softmax')(hidden_layer)\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(f\"Run {run + 1}/{num_runs} started...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            epochs=1000, \n",
    "            batch_size=int(X_train.shape[0] * 0.05), \n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=verbose_run\n",
    "        )\n",
    "        verbose_run = 0 # Suppress detailed output for multiple runs\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
    "        y_pred = model.predict(test_X, verbose=0)\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_true_classes = test_y.argmax(axis=1)\n",
    "\n",
    "        # Compute metrics\n",
    "        balanced_acc = balanced_accuracy_score(test_y, y_pred)\n",
    "        roc_auc = roc_auc_score(test_y, y_pred, multi_class='ovr')\n",
    "        pr_auc = average_precision_score(test_y, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n",
    "        mcc = matthews_corrcoef(y_true_classes, y_pred_classes)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_storage['test_loss'].append(test_loss)\n",
    "        metrics_storage['test_accuracy'].append(test_acc)\n",
    "        metrics_storage['balanced_accuracy'].append(balanced_acc)\n",
    "        metrics_storage['roc_auc'].append(roc_auc)\n",
    "        metrics_storage['pr_auc'].append(pr_auc)\n",
    "        metrics_storage['f2'].append(f2)\n",
    "        metrics_storage['mcc'].append(mcc)\n",
    "\n",
    "        # Store classification report metrics\n",
    "        report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "        for label, values in report.items():\n",
    "            # Check if the value is a dictionary (e.g., 'precision', 'recall', 'f1-score')\n",
    "            if isinstance(values, dict):\n",
    "                for metric, value in values.items():\n",
    "                    metrics_storage[f\"{label}_{metric}\"].append(value)\n",
    "            else:\n",
    "                # Handle scalar values (like 'accuracy')\n",
    "                metrics_storage[label].append(values)\n",
    "\n",
    "    # Average the metrics over all runs\n",
    "    print(\"\\nAggregated Metrics:\")\n",
    "    for metric, values in metrics_storage.items():\n",
    "        avg_value = np.mean(values)\n",
    "        print(f\"{metric}: {avg_value:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 58ms/step - accuracy: 0.4987 - loss: 1.6199 - val_accuracy: 0.8764 - val_loss: 0.6017\n",
      "Epoch 2/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8723 - loss: 0.5206 - val_accuracy: 0.9471 - val_loss: 0.2632\n",
      "Epoch 3/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9299 - loss: 0.2774 - val_accuracy: 0.9648 - val_loss: 0.1876\n",
      "Epoch 4/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.2042 - val_accuracy: 0.9670 - val_loss: 0.1483\n",
      "Epoch 5/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9667 - loss: 0.1481 - val_accuracy: 0.9664 - val_loss: 0.1266\n",
      "Epoch 6/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9695 - loss: 0.1273 - val_accuracy: 0.9672 - val_loss: 0.1102\n",
      "Epoch 7/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9701 - loss: 0.1174 - val_accuracy: 0.9675 - val_loss: 0.1000\n",
      "Epoch 8/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.1049 - val_accuracy: 0.9717 - val_loss: 0.0912\n",
      "Epoch 9/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9752 - loss: 0.0925 - val_accuracy: 0.9733 - val_loss: 0.0827\n",
      "Epoch 10/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9763 - loss: 0.0873 - val_accuracy: 0.9772 - val_loss: 0.0765\n",
      "Epoch 11/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9775 - loss: 0.0806 - val_accuracy: 0.9779 - val_loss: 0.0723\n",
      "Epoch 12/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9799 - loss: 0.0756 - val_accuracy: 0.9819 - val_loss: 0.0686\n",
      "Epoch 13/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9807 - loss: 0.0733 - val_accuracy: 0.9783 - val_loss: 0.0660\n",
      "Epoch 14/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9805 - loss: 0.0716 - val_accuracy: 0.9831 - val_loss: 0.0633\n",
      "Epoch 15/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0634 - val_accuracy: 0.9843 - val_loss: 0.0610\n",
      "Epoch 16/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9833 - loss: 0.0628 - val_accuracy: 0.9800 - val_loss: 0.0583\n",
      "Epoch 17/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9835 - loss: 0.0620 - val_accuracy: 0.9841 - val_loss: 0.0554\n",
      "Epoch 18/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0584 - val_accuracy: 0.9849 - val_loss: 0.0534\n",
      "Epoch 19/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9835 - loss: 0.0597 - val_accuracy: 0.9846 - val_loss: 0.0516\n",
      "Epoch 20/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.0536 - val_accuracy: 0.9855 - val_loss: 0.0514\n",
      "Epoch 21/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9847 - loss: 0.0542 - val_accuracy: 0.9858 - val_loss: 0.0500\n",
      "Epoch 22/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9852 - loss: 0.0533 - val_accuracy: 0.9849 - val_loss: 0.0481\n",
      "Epoch 23/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9857 - loss: 0.0493 - val_accuracy: 0.9858 - val_loss: 0.0469\n",
      "Epoch 24/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9866 - loss: 0.0462 - val_accuracy: 0.9857 - val_loss: 0.0456\n",
      "Epoch 25/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9859 - loss: 0.0475 - val_accuracy: 0.9861 - val_loss: 0.0441\n",
      "Epoch 26/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9851 - loss: 0.0484 - val_accuracy: 0.9859 - val_loss: 0.0437\n",
      "Epoch 27/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9865 - loss: 0.0470 - val_accuracy: 0.9866 - val_loss: 0.0426\n",
      "Epoch 28/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9871 - loss: 0.0446 - val_accuracy: 0.9866 - val_loss: 0.0416\n",
      "Epoch 29/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9870 - loss: 0.0421 - val_accuracy: 0.9867 - val_loss: 0.0410\n",
      "Epoch 30/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9870 - loss: 0.0446 - val_accuracy: 0.9866 - val_loss: 0.0397\n",
      "Epoch 31/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9867 - loss: 0.0420 - val_accuracy: 0.9866 - val_loss: 0.0393\n",
      "Epoch 32/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9868 - loss: 0.0398 - val_accuracy: 0.9867 - val_loss: 0.0391\n",
      "Epoch 33/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9871 - loss: 0.0412 - val_accuracy: 0.9867 - val_loss: 0.0379\n",
      "Epoch 34/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.0420 - val_accuracy: 0.9870 - val_loss: 0.0375\n",
      "Epoch 35/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9874 - loss: 0.0381 - val_accuracy: 0.9870 - val_loss: 0.0369\n",
      "Epoch 36/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9880 - loss: 0.0376 - val_accuracy: 0.9871 - val_loss: 0.0359\n",
      "Epoch 37/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9877 - loss: 0.0374 - val_accuracy: 0.9874 - val_loss: 0.0353\n",
      "Epoch 38/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9877 - loss: 0.0368 - val_accuracy: 0.9873 - val_loss: 0.0348\n",
      "Epoch 39/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9880 - loss: 0.0350 - val_accuracy: 0.9871 - val_loss: 0.0357\n",
      "Epoch 40/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9882 - loss: 0.0361 - val_accuracy: 0.9878 - val_loss: 0.0337\n",
      "Epoch 41/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9884 - loss: 0.0358 - val_accuracy: 0.9881 - val_loss: 0.0335\n",
      "Epoch 42/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9875 - loss: 0.0371 - val_accuracy: 0.9880 - val_loss: 0.0330\n",
      "Epoch 43/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9878 - loss: 0.0349 - val_accuracy: 0.9878 - val_loss: 0.0330\n",
      "Epoch 44/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9882 - loss: 0.0345 - val_accuracy: 0.9885 - val_loss: 0.0323\n",
      "Epoch 45/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9875 - loss: 0.0351 - val_accuracy: 0.9889 - val_loss: 0.0318\n",
      "Epoch 46/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0320 - val_accuracy: 0.9881 - val_loss: 0.0316\n",
      "Epoch 47/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9882 - loss: 0.0328 - val_accuracy: 0.9888 - val_loss: 0.0315\n",
      "Epoch 48/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9888 - loss: 0.0341 - val_accuracy: 0.9883 - val_loss: 0.0322\n",
      "Epoch 49/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9880 - loss: 0.0331 - val_accuracy: 0.9881 - val_loss: 0.0319\n",
      "Epoch 50/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9889 - loss: 0.0337 - val_accuracy: 0.9889 - val_loss: 0.0312\n",
      "Epoch 51/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9875 - loss: 0.0331 - val_accuracy: 0.9893 - val_loss: 0.0307\n",
      "Epoch 52/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9895 - loss: 0.0303 - val_accuracy: 0.9880 - val_loss: 0.0310\n",
      "Epoch 53/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9887 - loss: 0.0320 - val_accuracy: 0.9884 - val_loss: 0.0309\n",
      "Epoch 54/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9884 - loss: 0.0311 - val_accuracy: 0.9889 - val_loss: 0.0293\n",
      "Epoch 55/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9893 - loss: 0.0308 - val_accuracy: 0.9892 - val_loss: 0.0291\n",
      "Epoch 56/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9897 - loss: 0.0289 - val_accuracy: 0.9897 - val_loss: 0.0299\n",
      "Epoch 57/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9899 - loss: 0.0300 - val_accuracy: 0.9890 - val_loss: 0.0295\n",
      "Epoch 58/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0305 - val_accuracy: 0.9889 - val_loss: 0.0290\n",
      "Epoch 59/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0290 - val_accuracy: 0.9895 - val_loss: 0.0286\n",
      "Epoch 60/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9897 - loss: 0.0299 - val_accuracy: 0.9875 - val_loss: 0.0325\n",
      "Epoch 61/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0297 - val_accuracy: 0.9890 - val_loss: 0.0288\n",
      "Epoch 62/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9893 - loss: 0.0297 - val_accuracy: 0.9891 - val_loss: 0.0286\n",
      "Epoch 63/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0300 - val_accuracy: 0.9898 - val_loss: 0.0283\n",
      "Epoch 64/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9899 - loss: 0.0291 - val_accuracy: 0.9890 - val_loss: 0.0282\n",
      "Epoch 65/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9901 - loss: 0.0272 - val_accuracy: 0.9898 - val_loss: 0.0279\n",
      "Epoch 66/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9901 - loss: 0.0287 - val_accuracy: 0.9899 - val_loss: 0.0280\n",
      "Epoch 67/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0270 - val_accuracy: 0.9890 - val_loss: 0.0275\n",
      "Epoch 68/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9899 - loss: 0.0283 - val_accuracy: 0.9889 - val_loss: 0.0277\n",
      "Epoch 69/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9898 - loss: 0.0277 - val_accuracy: 0.9891 - val_loss: 0.0281\n",
      "Epoch 70/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9896 - loss: 0.0292 - val_accuracy: 0.9894 - val_loss: 0.0281\n",
      "Epoch 71/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9905 - loss: 0.0286 - val_accuracy: 0.9894 - val_loss: 0.0271\n",
      "Epoch 72/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9888 - loss: 0.0300 - val_accuracy: 0.9891 - val_loss: 0.0277\n",
      "Epoch 73/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9898 - loss: 0.0280 - val_accuracy: 0.9899 - val_loss: 0.0272\n",
      "Epoch 74/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9895 - loss: 0.0288 - val_accuracy: 0.9892 - val_loss: 0.0280\n",
      "Epoch 75/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.0276 - val_accuracy: 0.9900 - val_loss: 0.0268\n",
      "Epoch 76/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9898 - loss: 0.0276 - val_accuracy: 0.9888 - val_loss: 0.0278\n",
      "Epoch 77/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9900 - loss: 0.0283 - val_accuracy: 0.9901 - val_loss: 0.0269\n",
      "Epoch 78/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9902 - loss: 0.0265 - val_accuracy: 0.9893 - val_loss: 0.0288\n",
      "Epoch 79/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9900 - loss: 0.0277 - val_accuracy: 0.9897 - val_loss: 0.0270\n",
      "Epoch 80/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9902 - loss: 0.0258 - val_accuracy: 0.9897 - val_loss: 0.0259\n",
      "Epoch 81/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9905 - loss: 0.0264 - val_accuracy: 0.9903 - val_loss: 0.0264\n",
      "Epoch 82/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9894 - loss: 0.0272 - val_accuracy: 0.9890 - val_loss: 0.0274\n",
      "Epoch 83/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9899 - loss: 0.0269 - val_accuracy: 0.9895 - val_loss: 0.0264\n",
      "Epoch 84/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9902 - loss: 0.0274 - val_accuracy: 0.9893 - val_loss: 0.0262\n",
      "Epoch 85/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9900 - loss: 0.0273 - val_accuracy: 0.9897 - val_loss: 0.0260\n",
      "Epoch 86/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9909 - loss: 0.0251 - val_accuracy: 0.9898 - val_loss: 0.0267\n",
      "Epoch 87/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9900 - loss: 0.0264 - val_accuracy: 0.9898 - val_loss: 0.0260\n",
      "Epoch 88/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9911 - loss: 0.0247 - val_accuracy: 0.9900 - val_loss: 0.0259\n",
      "Epoch 89/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9896 - loss: 0.0270 - val_accuracy: 0.9898 - val_loss: 0.0260\n",
      "Epoch 90/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9905 - loss: 0.0254 - val_accuracy: 0.9900 - val_loss: 0.0259\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.5495\n",
      "test_accuracy: 0.8649\n",
      "roc_auc: 0.6181\n",
      "pr_auc: 0.8334\n",
      "f2: 0.8431\n",
      "mcc: 0.4495\n",
      "0_precision: 0.8627\n",
      "0_recall: 0.9989\n",
      "0_f1-score: 0.9240\n",
      "0_support: 9117.0000\n",
      "1_precision: 0.1556\n",
      "1_recall: 0.1400\n",
      "1_f1-score: 0.1474\n",
      "1_support: 10.0000\n",
      "2_precision: 0.1765\n",
      "2_recall: 0.1765\n",
      "2_f1-score: 0.1765\n",
      "2_support: 34.0000\n",
      "3_precision: 0.5831\n",
      "3_recall: 0.3199\n",
      "3_f1-score: 0.3832\n",
      "3_support: 1781.0000\n",
      "4_precision: 0.5639\n",
      "4_recall: 0.5320\n",
      "4_f1-score: 0.5459\n",
      "4_support: 653.0000\n",
      "5_precision: 0.2000\n",
      "5_recall: 0.1000\n",
      "5_f1-score: 0.1333\n",
      "5_support: 2.0000\n",
      "6_precision: 0.1500\n",
      "6_recall: 0.2000\n",
      "6_f1-score: 0.1714\n",
      "6_support: 3.0000\n",
      "accuracy: 0.8649\n",
      "macro avg_precision: 0.3845\n",
      "macro avg_recall: 0.3525\n",
      "macro avg_f1-score: 0.3545\n",
      "macro avg_support: 11600.0000\n",
      "weighted avg_precision: 0.8000\n",
      "weighted avg_recall: 0.8649\n",
      "weighted avg_f1-score: 0.8165\n",
      "weighted avg_support: 11600.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"shuttle_train.csv\", \"shuttle_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - accuracy: 0.3703 - loss: 1.9021 - val_accuracy: 0.3646 - val_loss: 1.6514\n",
      "Epoch 2/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.3975 - loss: 1.5202 - val_accuracy: 0.4973 - val_loss: 1.2262\n",
      "Epoch 3/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4672 - loss: 1.2548 - val_accuracy: 0.4949 - val_loss: 1.1907\n",
      "Epoch 4/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.4741 - loss: 1.2232 - val_accuracy: 0.4979 - val_loss: 1.1849\n",
      "Epoch 5/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.4696 - loss: 1.2116 - val_accuracy: 0.4977 - val_loss: 1.1827\n",
      "Epoch 6/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.4809 - loss: 1.2090 - val_accuracy: 0.4977 - val_loss: 1.1822\n",
      "Epoch 7/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.4771 - loss: 1.2053 - val_accuracy: 0.4977 - val_loss: 1.1812\n",
      "Epoch 8/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.4830 - loss: 1.2051 - val_accuracy: 0.4977 - val_loss: 1.1807\n",
      "Epoch 9/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4839 - loss: 1.2024 - val_accuracy: 0.4977 - val_loss: 1.1802\n",
      "Epoch 10/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.4889 - loss: 1.2014 - val_accuracy: 0.4977 - val_loss: 1.1803\n",
      "Epoch 11/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4896 - loss: 1.2009 - val_accuracy: 0.4977 - val_loss: 1.1806\n",
      "Epoch 12/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.4871 - loss: 1.2018 - val_accuracy: 0.4979 - val_loss: 1.1800\n",
      "Epoch 13/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.4883 - loss: 1.1978 - val_accuracy: 0.4977 - val_loss: 1.1804\n",
      "Epoch 14/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4965 - loss: 1.1988 - val_accuracy: 0.4979 - val_loss: 1.1803\n",
      "Epoch 15/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.4878 - loss: 1.1992 - val_accuracy: 0.4977 - val_loss: 1.1799\n",
      "Epoch 16/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4948 - loss: 1.1982 - val_accuracy: 0.4977 - val_loss: 1.1797\n",
      "Epoch 17/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4932 - loss: 1.1967 - val_accuracy: 0.4977 - val_loss: 1.1822\n",
      "Epoch 18/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4962 - loss: 1.2036 - val_accuracy: 0.4979 - val_loss: 1.1811\n",
      "Epoch 19/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4970 - loss: 1.1941 - val_accuracy: 0.4979 - val_loss: 1.1801\n",
      "Epoch 20/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4908 - loss: 1.1960 - val_accuracy: 0.4977 - val_loss: 1.1800\n",
      "Epoch 21/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4919 - loss: 1.1967 - val_accuracy: 0.4977 - val_loss: 1.1797\n",
      "Epoch 22/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.4957 - loss: 1.1953 - val_accuracy: 0.4979 - val_loss: 1.1798\n",
      "Epoch 23/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4964 - loss: 1.1962 - val_accuracy: 0.4979 - val_loss: 1.1799\n",
      "Epoch 24/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4967 - loss: 1.1943 - val_accuracy: 0.4977 - val_loss: 1.1797\n",
      "Epoch 25/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4959 - loss: 1.1930 - val_accuracy: 0.4977 - val_loss: 1.1812\n",
      "Epoch 26/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4962 - loss: 1.1997 - val_accuracy: 0.4979 - val_loss: 1.1841\n",
      "Epoch 27/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.4971 - loss: 1.1984 - val_accuracy: 0.4977 - val_loss: 1.1812\n",
      "Epoch 28/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4964 - loss: 1.1955 - val_accuracy: 0.4979 - val_loss: 1.1797\n",
      "Epoch 29/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4974 - loss: 1.1952 - val_accuracy: 0.4979 - val_loss: 1.1795\n",
      "Epoch 30/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4972 - loss: 1.1944 - val_accuracy: 0.4979 - val_loss: 1.1803\n",
      "Epoch 31/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4963 - loss: 1.1930 - val_accuracy: 0.4977 - val_loss: 1.1799\n",
      "Epoch 32/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4966 - loss: 1.1922 - val_accuracy: 0.4977 - val_loss: 1.1798\n",
      "Epoch 33/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.4988 - loss: 1.1900 - val_accuracy: 0.4977 - val_loss: 1.1797\n",
      "Epoch 34/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4966 - loss: 1.1921 - val_accuracy: 0.4977 - val_loss: 1.1800\n",
      "Epoch 35/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4952 - loss: 1.1942 - val_accuracy: 0.4979 - val_loss: 1.1801\n",
      "Epoch 36/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.4977 - loss: 1.1948 - val_accuracy: 0.4977 - val_loss: 1.1809\n",
      "Epoch 37/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4962 - loss: 1.1931 - val_accuracy: 0.4979 - val_loss: 1.1796\n",
      "Epoch 38/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4982 - loss: 1.1901 - val_accuracy: 0.4977 - val_loss: 1.1794\n",
      "Epoch 39/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.4975 - loss: 1.1896 - val_accuracy: 0.4977 - val_loss: 1.1799\n",
      "Epoch 40/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4973 - loss: 1.1935 - val_accuracy: 0.4979 - val_loss: 1.1805\n",
      "Epoch 41/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4972 - loss: 1.1937 - val_accuracy: 0.4977 - val_loss: 1.1797\n",
      "Epoch 42/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.4963 - loss: 1.1924 - val_accuracy: 0.4977 - val_loss: 1.1794\n",
      "Epoch 43/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4969 - loss: 1.1917 - val_accuracy: 0.4977 - val_loss: 1.1800\n",
      "Epoch 44/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.4972 - loss: 1.1927 - val_accuracy: 0.4977 - val_loss: 1.1799\n",
      "Epoch 45/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4968 - loss: 1.1905 - val_accuracy: 0.4979 - val_loss: 1.1796\n",
      "Epoch 46/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4968 - loss: 1.1916 - val_accuracy: 0.4977 - val_loss: 1.1798\n",
      "Epoch 47/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4985 - loss: 1.1901 - val_accuracy: 0.4977 - val_loss: 1.1804\n",
      "Epoch 48/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.4990 - loss: 1.1904 - val_accuracy: 0.4977 - val_loss: 1.1798\n",
      "Epoch 49/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4966 - loss: 1.1884 - val_accuracy: 0.4955 - val_loss: 1.1805\n",
      "Epoch 50/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4966 - loss: 1.1915 - val_accuracy: 0.4979 - val_loss: 1.1795\n",
      "Epoch 51/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.4978 - loss: 1.1896 - val_accuracy: 0.4979 - val_loss: 1.1795\n",
      "Epoch 52/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.4973 - loss: 1.1902 - val_accuracy: 0.4977 - val_loss: 1.1795\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 1.3231\n",
      "test_accuracy: 0.4712\n",
      "roc_auc: 0.5394\n",
      "pr_auc: 0.3996\n",
      "f2: 0.3959\n",
      "mcc: 0.0602\n",
      "0_precision: 0.3959\n",
      "0_recall: 0.2478\n",
      "0_f1-score: 0.1859\n",
      "0_support: 42368.0000\n",
      "1_precision: 0.3977\n",
      "1_recall: 0.7725\n",
      "1_f1-score: 0.5248\n",
      "1_support: 56661.0000\n",
      "2_precision: 0.0727\n",
      "2_recall: 0.0604\n",
      "2_f1-score: 0.0660\n",
      "2_support: 7151.0000\n",
      "3_precision: 0.0000\n",
      "3_recall: 0.0000\n",
      "3_f1-score: 0.0000\n",
      "3_support: 549.0000\n",
      "4_precision: 0.0000\n",
      "4_recall: 0.0000\n",
      "4_f1-score: 0.0000\n",
      "4_support: 1899.0000\n",
      "5_precision: 0.1085\n",
      "5_recall: 0.0044\n",
      "5_f1-score: 0.0085\n",
      "5_support: 3473.0000\n",
      "6_precision: 0.1016\n",
      "6_recall: 0.0092\n",
      "6_f1-score: 0.0168\n",
      "6_support: 4102.0000\n",
      "accuracy: 0.4712\n",
      "macro avg_precision: 0.1538\n",
      "macro avg_recall: 0.1563\n",
      "macro avg_f1-score: 0.1146\n",
      "macro avg_support: 116203.0000\n",
      "weighted avg_precision: 0.3496\n",
      "weighted avg_recall: 0.4712\n",
      "weighted avg_f1-score: 0.3286\n",
      "weighted avg_support: 116203.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"covtype_train.csv\", \"covtype_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 292ms/step - accuracy: 0.7939 - loss: 2.9304 - val_accuracy: 0.9551 - val_loss: 2.1358\n",
      "Epoch 2/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9554 - loss: 1.5575 - val_accuracy: 0.9551 - val_loss: 0.3177\n",
      "Epoch 3/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9556 - loss: 0.3429 - val_accuracy: 0.9551 - val_loss: 0.3270\n",
      "Epoch 4/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9553 - loss: 0.3149 - val_accuracy: 0.9551 - val_loss: 0.2696\n",
      "Epoch 5/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9553 - loss: 0.2895 - val_accuracy: 0.9551 - val_loss: 0.2675\n",
      "Epoch 6/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.9552 - loss: 0.2832 - val_accuracy: 0.9551 - val_loss: 0.2659\n",
      "Epoch 7/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9548 - loss: 0.2825 - val_accuracy: 0.9551 - val_loss: 0.2636\n",
      "Epoch 8/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9551 - loss: 0.2781 - val_accuracy: 0.9551 - val_loss: 0.2624\n",
      "Epoch 9/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9554 - loss: 0.2755 - val_accuracy: 0.9551 - val_loss: 0.2617\n",
      "Epoch 10/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9550 - loss: 0.2763 - val_accuracy: 0.9551 - val_loss: 0.2619\n",
      "Epoch 11/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9551 - loss: 0.2747 - val_accuracy: 0.9551 - val_loss: 0.2611\n",
      "Epoch 12/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9552 - loss: 0.2732 - val_accuracy: 0.9551 - val_loss: 0.2610\n",
      "Epoch 13/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9556 - loss: 0.2707 - val_accuracy: 0.9551 - val_loss: 0.2600\n",
      "Epoch 14/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9551 - loss: 0.2729 - val_accuracy: 0.9551 - val_loss: 0.2610\n",
      "Epoch 15/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9551 - loss: 0.2716 - val_accuracy: 0.9551 - val_loss: 0.2600\n",
      "Epoch 16/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9553 - loss: 0.2692 - val_accuracy: 0.9551 - val_loss: 0.2605\n",
      "Epoch 17/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.9550 - loss: 0.2708 - val_accuracy: 0.9551 - val_loss: 0.2596\n",
      "Epoch 18/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9549 - loss: 0.2704 - val_accuracy: 0.9551 - val_loss: 0.2597\n",
      "Epoch 19/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9551 - loss: 0.2689 - val_accuracy: 0.9551 - val_loss: 0.2606\n",
      "Epoch 20/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9552 - loss: 0.2683 - val_accuracy: 0.9551 - val_loss: 0.2593\n",
      "Epoch 21/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9551 - loss: 0.2675 - val_accuracy: 0.9551 - val_loss: 0.2596\n",
      "Epoch 22/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.9552 - loss: 0.2672 - val_accuracy: 0.9551 - val_loss: 0.2593\n",
      "Epoch 23/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9553 - loss: 0.2662 - val_accuracy: 0.9551 - val_loss: 0.2590\n",
      "Epoch 24/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9549 - loss: 0.2684 - val_accuracy: 0.9551 - val_loss: 0.2593\n",
      "Epoch 25/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9554 - loss: 0.2651 - val_accuracy: 0.9551 - val_loss: 0.2598\n",
      "Epoch 26/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - accuracy: 0.9552 - loss: 0.2665 - val_accuracy: 0.9551 - val_loss: 0.2592\n",
      "Epoch 27/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.9550 - loss: 0.2671 - val_accuracy: 0.9551 - val_loss: 0.2592\n",
      "Epoch 28/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9553 - loss: 0.2656 - val_accuracy: 0.9551 - val_loss: 0.2598\n",
      "Epoch 29/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9553 - loss: 0.2660 - val_accuracy: 0.9551 - val_loss: 0.2588\n",
      "Epoch 30/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.9552 - loss: 0.2661 - val_accuracy: 0.9551 - val_loss: 0.2592\n",
      "Epoch 31/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9552 - loss: 0.2659 - val_accuracy: 0.9551 - val_loss: 0.2591\n",
      "Epoch 32/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - accuracy: 0.9555 - loss: 0.2638 - val_accuracy: 0.9551 - val_loss: 0.2588\n",
      "Epoch 33/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9555 - loss: 0.2644 - val_accuracy: 0.9551 - val_loss: 0.2596\n",
      "Epoch 34/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9552 - loss: 0.2652 - val_accuracy: 0.9551 - val_loss: 0.2587\n",
      "Epoch 35/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9552 - loss: 0.2649 - val_accuracy: 0.9551 - val_loss: 0.2592\n",
      "Epoch 36/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.9548 - loss: 0.2670 - val_accuracy: 0.9551 - val_loss: 0.2598\n",
      "Epoch 37/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.9548 - loss: 0.2673 - val_accuracy: 0.9551 - val_loss: 0.2587\n",
      "Epoch 38/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9556 - loss: 0.2635 - val_accuracy: 0.9551 - val_loss: 0.2609\n",
      "Epoch 39/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9552 - loss: 0.2653 - val_accuracy: 0.9551 - val_loss: 0.2590\n",
      "Epoch 40/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9553 - loss: 0.2636 - val_accuracy: 0.9551 - val_loss: 0.2589\n",
      "Epoch 41/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9552 - loss: 0.2642 - val_accuracy: 0.9551 - val_loss: 0.2596\n",
      "Epoch 42/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9550 - loss: 0.2654 - val_accuracy: 0.9551 - val_loss: 0.2592\n",
      "Epoch 43/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9545 - loss: 0.2692 - val_accuracy: 0.9551 - val_loss: 0.2619\n",
      "Epoch 44/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - accuracy: 0.9555 - loss: 0.2638 - val_accuracy: 0.9551 - val_loss: 0.2589\n",
      "Epoch 45/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9551 - loss: 0.2645 - val_accuracy: 0.9551 - val_loss: 0.2603\n",
      "Epoch 46/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.9550 - loss: 0.2654 - val_accuracy: 0.9551 - val_loss: 0.2593\n",
      "Epoch 47/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - accuracy: 0.9548 - loss: 0.2664 - val_accuracy: 0.9551 - val_loss: 0.2590\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.9859\n",
      "test_accuracy: 0.9581\n",
      "roc_auc: 0.6001\n",
      "pr_auc: 0.9106\n",
      "f2: 0.9501\n",
      "mcc: 0.1473\n",
      "0_precision: 0.9583\n",
      "0_recall: 0.9999\n",
      "0_f1-score: 0.9787\n",
      "0_support: 194557.0000\n",
      "1_precision: 0.3045\n",
      "1_recall: 0.1874\n",
      "1_f1-score: 0.2162\n",
      "1_support: 3178.0000\n",
      "2_precision: 0.0000\n",
      "2_recall: 0.0000\n",
      "2_f1-score: 0.0000\n",
      "2_support: 2496.0000\n",
      "3_precision: 0.2933\n",
      "3_recall: 0.0006\n",
      "3_f1-score: 0.0011\n",
      "3_support: 2083.0000\n",
      "4_precision: 0.1990\n",
      "4_recall: 0.0829\n",
      "4_f1-score: 0.1171\n",
      "4_support: 463.0000\n",
      "5_precision: 0.0000\n",
      "5_recall: 0.0000\n",
      "5_f1-score: 0.0000\n",
      "5_support: 441.0000\n",
      "6_precision: 0.0000\n",
      "6_recall: 0.0000\n",
      "6_f1-score: 0.0000\n",
      "6_support: 204.0000\n",
      "7_precision: 0.0000\n",
      "7_recall: 0.0000\n",
      "7_f1-score: 0.0000\n",
      "7_support: 196.0000\n",
      "8_precision: 0.0000\n",
      "8_recall: 0.0000\n",
      "8_f1-score: 0.0000\n",
      "8_support: 53.0000\n",
      "9_precision: 0.0000\n",
      "9_recall: 0.0000\n",
      "9_f1-score: 0.0000\n",
      "9_support: 11.0000\n",
      "10_precision: 0.0000\n",
      "10_recall: 0.0000\n",
      "10_f1-score: 0.0000\n",
      "10_support: 6.0000\n",
      "11_precision: 0.0000\n",
      "11_recall: 0.0000\n",
      "11_f1-score: 0.0000\n",
      "11_support: 4.0000\n",
      "12_precision: 0.0000\n",
      "12_recall: 0.0000\n",
      "12_f1-score: 0.0000\n",
      "12_support: 4.0000\n",
      "13_precision: 0.0000\n",
      "13_recall: 0.0000\n",
      "13_f1-score: 0.0000\n",
      "13_support: 2.0000\n",
      "14_precision: 0.0000\n",
      "14_recall: 0.0000\n",
      "14_f1-score: 0.0000\n",
      "14_support: 2.0000\n",
      "15_precision: 0.0000\n",
      "15_recall: 0.0000\n",
      "15_f1-score: 0.0000\n",
      "15_support: 2.0000\n",
      "16_precision: 0.0000\n",
      "16_recall: 0.0000\n",
      "16_f1-score: 0.0000\n",
      "16_support: 1.0000\n",
      "17_precision: 0.0000\n",
      "17_recall: 0.0000\n",
      "17_f1-score: 0.0000\n",
      "17_support: 2.0000\n",
      "18_precision: 0.0000\n",
      "18_recall: 0.0000\n",
      "18_f1-score: 0.0000\n",
      "18_support: 1.0000\n",
      "19_precision: 0.0000\n",
      "19_recall: 0.0000\n",
      "19_f1-score: 0.0000\n",
      "19_support: 1.0000\n",
      "20_precision: 0.0000\n",
      "20_recall: 0.0000\n",
      "20_f1-score: 0.0000\n",
      "20_support: 1.0000\n",
      "accuracy: 0.9581\n",
      "macro avg_precision: 0.0836\n",
      "macro avg_recall: 0.0605\n",
      "macro avg_f1-score: 0.0625\n",
      "macro avg_support: 203708.0000\n",
      "weighted avg_precision: 0.9235\n",
      "weighted avg_recall: 0.9581\n",
      "weighted avg_f1-score: 0.9384\n",
      "weighted avg_support: 203708.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'normal.': 0, 'satan.': 1, 'ipsweep.': 2, 'portsweep.': 3, 'nmap.': 4,\n",
    "    'back.': 5, 'warezclient.': 6, 'teardrop.': 7, 'pod.': 8, 'guess_passwd.': 9,\n",
    "    'buffer_overflow.': 10, 'land.': 11, 'warezmaster.': 12, 'imap.': 13, 'rootkit.': 14,\n",
    "    'loadmodule.': 15, 'multihop.': 16, 'ftp_write.': 17, 'phf.': 18, 'perl.': 19, 'spy.': 20\n",
    "}\n",
    "\n",
    "run_model(\"kdd_train.csv\", \"kdd_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose output only for first run...\n",
      "Run 1/5 started...\n",
      "Epoch 1/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - accuracy: 0.6664 - loss: 1.9174 - val_accuracy: 0.8467 - val_loss: 0.9577\n",
      "Epoch 2/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8459 - loss: 0.8549 - val_accuracy: 0.8467 - val_loss: 0.6859\n",
      "Epoch 3/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8459 - loss: 0.6944 - val_accuracy: 0.8465 - val_loss: 0.6330\n",
      "Epoch 4/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8457 - loss: 0.6614 - val_accuracy: 0.8467 - val_loss: 0.6251\n",
      "Epoch 5/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8463 - loss: 0.6502 - val_accuracy: 0.8467 - val_loss: 0.6186\n",
      "Epoch 6/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8465 - loss: 0.6455 - val_accuracy: 0.8467 - val_loss: 0.6158\n",
      "Epoch 7/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8451 - loss: 0.6417 - val_accuracy: 0.8467 - val_loss: 0.6116\n",
      "Epoch 8/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8473 - loss: 0.6337 - val_accuracy: 0.8467 - val_loss: 0.6107\n",
      "Epoch 9/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8476 - loss: 0.6246 - val_accuracy: 0.8467 - val_loss: 0.6048\n",
      "Epoch 10/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8470 - loss: 0.6217 - val_accuracy: 0.8467 - val_loss: 0.6008\n",
      "Epoch 11/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8470 - loss: 0.6173 - val_accuracy: 0.8467 - val_loss: 0.5964\n",
      "Epoch 12/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8477 - loss: 0.6095 - val_accuracy: 0.8467 - val_loss: 0.5910\n",
      "Epoch 13/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8471 - loss: 0.6086 - val_accuracy: 0.8467 - val_loss: 0.5860\n",
      "Epoch 14/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8461 - loss: 0.6072 - val_accuracy: 0.8467 - val_loss: 0.5775\n",
      "Epoch 15/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8485 - loss: 0.5899 - val_accuracy: 0.8467 - val_loss: 0.5680\n",
      "Epoch 16/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8464 - loss: 0.5841 - val_accuracy: 0.8467 - val_loss: 0.5555\n",
      "Epoch 17/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8453 - loss: 0.5713 - val_accuracy: 0.8467 - val_loss: 0.5421\n",
      "Epoch 18/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8466 - loss: 0.5541 - val_accuracy: 0.8467 - val_loss: 0.5287\n",
      "Epoch 19/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8538 - loss: 0.5445 - val_accuracy: 0.8715 - val_loss: 0.5200\n",
      "Epoch 20/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8699 - loss: 0.5385 - val_accuracy: 0.8849 - val_loss: 0.5092\n",
      "Epoch 21/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8789 - loss: 0.5261 - val_accuracy: 0.8921 - val_loss: 0.5025\n",
      "Epoch 22/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8867 - loss: 0.5203 - val_accuracy: 0.8929 - val_loss: 0.4947\n",
      "Epoch 23/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8894 - loss: 0.5167 - val_accuracy: 0.8919 - val_loss: 0.4919\n",
      "Epoch 24/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8879 - loss: 0.5179 - val_accuracy: 0.8915 - val_loss: 0.4875\n",
      "Epoch 25/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8888 - loss: 0.5124 - val_accuracy: 0.8922 - val_loss: 0.4864\n",
      "Epoch 26/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8883 - loss: 0.5138 - val_accuracy: 0.8921 - val_loss: 0.4838\n",
      "Epoch 27/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8875 - loss: 0.5126 - val_accuracy: 0.8929 - val_loss: 0.4897\n",
      "Epoch 28/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8895 - loss: 0.5092 - val_accuracy: 0.8918 - val_loss: 0.4833\n",
      "Epoch 29/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8867 - loss: 0.5134 - val_accuracy: 0.8898 - val_loss: 0.4844\n",
      "Epoch 30/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8857 - loss: 0.5119 - val_accuracy: 0.8912 - val_loss: 0.4837\n",
      "Epoch 31/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8884 - loss: 0.5113 - val_accuracy: 0.8925 - val_loss: 0.4851\n",
      "Epoch 32/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8889 - loss: 0.5123 - val_accuracy: 0.8921 - val_loss: 0.4795\n",
      "Epoch 33/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8899 - loss: 0.5003 - val_accuracy: 0.8924 - val_loss: 0.4801\n",
      "Epoch 34/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8910 - loss: 0.4976 - val_accuracy: 0.8915 - val_loss: 0.4795\n",
      "Epoch 35/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8900 - loss: 0.5035 - val_accuracy: 0.8919 - val_loss: 0.4798\n",
      "Epoch 36/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8917 - loss: 0.4958 - val_accuracy: 0.8922 - val_loss: 0.4801\n",
      "Epoch 37/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8901 - loss: 0.4980 - val_accuracy: 0.8921 - val_loss: 0.4792\n",
      "Epoch 38/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8892 - loss: 0.5006 - val_accuracy: 0.8922 - val_loss: 0.4809\n",
      "Epoch 39/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8898 - loss: 0.4995 - val_accuracy: 0.8919 - val_loss: 0.4790\n",
      "Epoch 40/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8914 - loss: 0.4945 - val_accuracy: 0.8918 - val_loss: 0.4771\n",
      "Epoch 41/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8916 - loss: 0.4937 - val_accuracy: 0.8922 - val_loss: 0.4806\n",
      "Epoch 42/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8910 - loss: 0.4976 - val_accuracy: 0.8908 - val_loss: 0.4786\n",
      "Epoch 43/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8890 - loss: 0.5049 - val_accuracy: 0.8908 - val_loss: 0.4804\n",
      "Epoch 44/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8858 - loss: 0.5051 - val_accuracy: 0.8914 - val_loss: 0.4797\n",
      "Epoch 45/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8899 - loss: 0.5005 - val_accuracy: 0.8903 - val_loss: 0.4801\n",
      "Epoch 46/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8885 - loss: 0.5043 - val_accuracy: 0.8914 - val_loss: 0.4802\n",
      "Epoch 47/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8881 - loss: 0.5060 - val_accuracy: 0.8907 - val_loss: 0.4828\n",
      "Epoch 48/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8869 - loss: 0.5040 - val_accuracy: 0.8915 - val_loss: 0.4779\n",
      "Epoch 49/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8890 - loss: 0.4998 - val_accuracy: 0.8920 - val_loss: 0.4779\n",
      "Epoch 50/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8902 - loss: 0.4982 - val_accuracy: 0.8917 - val_loss: 0.4766\n",
      "Epoch 51/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8895 - loss: 0.5010 - val_accuracy: 0.8910 - val_loss: 0.4878\n",
      "Epoch 52/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8900 - loss: 0.5093 - val_accuracy: 0.8919 - val_loss: 0.4778\n",
      "Epoch 53/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8900 - loss: 0.4975 - val_accuracy: 0.8903 - val_loss: 0.4819\n",
      "Epoch 54/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8853 - loss: 0.5048 - val_accuracy: 0.8913 - val_loss: 0.4776\n",
      "Epoch 55/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8890 - loss: 0.4996 - val_accuracy: 0.8914 - val_loss: 0.4792\n",
      "Epoch 56/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8896 - loss: 0.5035 - val_accuracy: 0.8914 - val_loss: 0.4779\n",
      "Epoch 57/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8907 - loss: 0.4925 - val_accuracy: 0.8919 - val_loss: 0.4765\n",
      "Epoch 58/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8914 - loss: 0.4920 - val_accuracy: 0.8910 - val_loss: 0.4768\n",
      "Epoch 59/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8908 - loss: 0.4926 - val_accuracy: 0.8923 - val_loss: 0.4780\n",
      "Epoch 60/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8909 - loss: 0.4956 - val_accuracy: 0.8920 - val_loss: 0.4767\n",
      "Epoch 61/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8888 - loss: 0.5010 - val_accuracy: 0.8918 - val_loss: 0.4756\n",
      "Epoch 62/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8907 - loss: 0.4915 - val_accuracy: 0.8918 - val_loss: 0.4755\n",
      "Epoch 63/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8899 - loss: 0.4941 - val_accuracy: 0.8914 - val_loss: 0.4761\n",
      "Epoch 64/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8901 - loss: 0.4956 - val_accuracy: 0.8919 - val_loss: 0.4771\n",
      "Epoch 65/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8899 - loss: 0.4994 - val_accuracy: 0.8911 - val_loss: 0.4784\n",
      "Epoch 66/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8908 - loss: 0.4968 - val_accuracy: 0.8919 - val_loss: 0.4768\n",
      "Epoch 67/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8894 - loss: 0.4979 - val_accuracy: 0.8920 - val_loss: 0.4768\n",
      "Epoch 68/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8903 - loss: 0.4971 - val_accuracy: 0.8925 - val_loss: 0.4792\n",
      "Epoch 69/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8911 - loss: 0.4933 - val_accuracy: 0.8905 - val_loss: 0.4788\n",
      "Epoch 70/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8859 - loss: 0.5055 - val_accuracy: 0.8920 - val_loss: 0.4767\n",
      "Epoch 71/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8889 - loss: 0.5017 - val_accuracy: 0.8918 - val_loss: 0.4758\n",
      "Epoch 72/1000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8884 - loss: 0.5013 - val_accuracy: 0.8922 - val_loss: 0.4766\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.6263\n",
      "test_accuracy: 0.8814\n",
      "roc_auc: 0.6358\n",
      "pr_auc: 0.8298\n",
      "f2: 0.8603\n",
      "mcc: 0.2846\n",
      "0_precision: 0.8831\n",
      "0_recall: 0.9963\n",
      "0_f1-score: 0.9354\n",
      "0_support: 26862.0000\n",
      "1_precision: 0.3696\n",
      "1_recall: 0.3196\n",
      "1_f1-score: 0.3416\n",
      "1_support: 2657.0000\n",
      "2_precision: 0.1948\n",
      "2_recall: 0.1974\n",
      "2_f1-score: 0.1961\n",
      "2_support: 908.0000\n",
      "3_precision: 0.1436\n",
      "3_recall: 0.1774\n",
      "3_f1-score: 0.1587\n",
      "3_support: 522.0000\n",
      "4_precision: 0.1697\n",
      "4_recall: 0.1679\n",
      "4_f1-score: 0.1688\n",
      "4_support: 293.0000\n",
      "5_precision: 0.1294\n",
      "5_recall: 0.0082\n",
      "5_f1-score: 0.0154\n",
      "5_support: 269.0000\n",
      "6_precision: 0.2000\n",
      "6_recall: 0.1948\n",
      "6_f1-score: 0.1974\n",
      "6_support: 116.0000\n",
      "7_precision: 0.0000\n",
      "7_recall: 0.0000\n",
      "7_f1-score: 0.0000\n",
      "7_support: 53.0000\n",
      "8_precision: 0.1478\n",
      "8_recall: 0.0773\n",
      "8_f1-score: 0.1015\n",
      "8_support: 44.0000\n",
      "accuracy: 0.8814\n",
      "macro avg_precision: 0.2487\n",
      "macro avg_recall: 0.2377\n",
      "macro avg_f1-score: 0.2350\n",
      "macro avg_support: 31724.0000\n",
      "weighted avg_precision: 0.7902\n",
      "weighted avg_recall: 0.8814\n",
      "weighted avg_f1-score: 0.8314\n",
      "weighted avg_support: 31724.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'Normal': 0, 'Darknet_Audio-Streaming': 1, 'Darknet_Chat': 2, 'Darknet_File-Transfer': 3, 'Darknet_VOIP': 4,\n",
    "    'Darknet_Video-Streaming': 5, 'Darknet_Email': 6, 'Darknet_Browsing': 7, 'Darknet_P2P': 8\n",
    "}\n",
    "\n",
    "run_model(\"darknet_train.csv\", \"darknet_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
