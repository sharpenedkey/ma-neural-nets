{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e1a833",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T00:35:47.834806Z",
     "iopub.status.busy": "2024-12-07T00:35:47.834423Z",
     "iopub.status.idle": "2024-12-07T00:35:47.844211Z",
     "shell.execute_reply": "2024-12-07T00:35:47.843211Z"
    },
    "papermill": {
     "duration": 0.017995,
     "end_time": "2024-12-07T00:35:47.846489",
     "exception": false,
     "start_time": "2024-12-07T00:35:47.828494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bf2b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:35:47.854306Z",
     "iopub.status.busy": "2024-12-07T00:35:47.853918Z",
     "iopub.status.idle": "2024-12-07T00:36:03.327844Z",
     "shell.execute_reply": "2024-12-07T00:36:03.326669Z"
    },
    "papermill": {
     "duration": 15.480666,
     "end_time": "2024-12-07T00:36:03.330569",
     "exception": false,
     "start_time": "2024-12-07T00:35:47.849903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score, average_precision_score, fbeta_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06edf71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:36:03.338437Z",
     "iopub.status.busy": "2024-12-07T00:36:03.337783Z",
     "iopub.status.idle": "2024-12-07T00:36:03.350630Z",
     "shell.execute_reply": "2024-12-07T00:36:03.349518Z"
    },
    "papermill": {
     "duration": 0.019136,
     "end_time": "2024-12-07T00:36:03.352889",
     "exception": false,
     "start_time": "2024-12-07T00:36:03.333753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa41ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:36:03.360860Z",
     "iopub.status.busy": "2024-12-07T00:36:03.359962Z",
     "iopub.status.idle": "2024-12-07T00:36:03.367878Z",
     "shell.execute_reply": "2024-12-07T00:36:03.366820Z"
    },
    "papermill": {
     "duration": 0.013957,
     "end_time": "2024-12-07T00:36:03.369936",
     "exception": false,
     "start_time": "2024-12-07T00:36:03.355979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom function to build hidden combination (i.e. convolution) layers\n",
    "\n",
    "def create_random_combination_layer(input_layer, combination_size, num_combinations, input_dim):\n",
    "    outputs = []\n",
    "    \n",
    "    for _ in range(num_combinations):\n",
    "        # First random feature selection\n",
    "        indices_1 = np.random.choice(input_dim, combination_size, replace=False)\n",
    "        indices_tensor_1 = tf.constant(indices_1, dtype=tf.int32)\n",
    "        \n",
    "        # First feature selection using Lambda layer\n",
    "        slice_layer_1 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_1, axis=1),  # Gather selected features\n",
    "            output_shape=(combination_size,)\n",
    "        )(input_layer)\n",
    "        \n",
    "        # Second random feature selection (after the first random selection)\n",
    "        indices_2 = np.random.choice(combination_size, combination_size, replace=False)\n",
    "        indices_tensor_2 = tf.constant(indices_2, dtype=tf.int32)\n",
    "        \n",
    "        # Second feature selection using Lambda layer\n",
    "        slice_layer_2 = Lambda(\n",
    "            lambda x: tf.gather(x, indices_tensor_2, axis=1),  # Apply a second feature selection\n",
    "            output_shape=(combination_size,)\n",
    "        )(slice_layer_1)\n",
    "\n",
    "        # Apply Dense layers on the final selected subset\n",
    "        selected_features = Dense(16, activation='relu')(\n",
    "            Dense(8, activation='relu')(\n",
    "                Dense(4, activation='relu')(slice_layer_2)\n",
    "            )\n",
    "        )\n",
    "        outputs.append(selected_features)\n",
    "    \n",
    "    # Concatenate the outputs from all the random feature combinations\n",
    "    return Concatenate()(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b51ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:36:03.377196Z",
     "iopub.status.busy": "2024-12-07T00:36:03.376831Z",
     "iopub.status.idle": "2024-12-07T00:36:03.386199Z",
     "shell.execute_reply": "2024-12-07T00:36:03.385041Z"
    },
    "papermill": {
     "duration": 0.015516,
     "end_time": "2024-12-07T00:36:03.388366",
     "exception": false,
     "start_time": "2024-12-07T00:36:03.372850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_largest_class(X, y):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by reducing the size of the largest class based on its\n",
    "    relative size to the second largest class.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Reduced X and y.\n",
    "    \"\"\"\n",
    "    # Count class frequencies\n",
    "    class_counts = Counter(y)\n",
    "    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    largest_class, largest_count = sorted_classes[0]\n",
    "    second_largest_count = sorted_classes[1][1]\n",
    "    \n",
    "    # Determine the target size for the largest class\n",
    "    if largest_count > 2 * second_largest_count:\n",
    "        target_size = largest_count // 2\n",
    "    else:\n",
    "        target_size = second_largest_count\n",
    "    \n",
    "    # Split the largest class\n",
    "    X_largest = X[y == largest_class]\n",
    "    y_largest = y[y == largest_class]\n",
    "    \n",
    "    # Resample the largest class to the target size\n",
    "    X_largest_reduced, y_largest_reduced = resample(\n",
    "        X_largest, y_largest, replace=False, n_samples=target_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Combine reduced largest class with the rest\n",
    "    X_rest = X[y != largest_class]\n",
    "    y_rest = y[y != largest_class]\n",
    "    X_final = pd.concat([X_rest, X_largest_reduced])\n",
    "    y_final = pd.concat([y_rest, y_largest_reduced])\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "\n",
    "def apply_smote_dynamic_with_reduction(X, y):\n",
    "    \"\"\"\n",
    "    Apply preprocessing to reduce the largest class, then apply SMOTE dynamically\n",
    "    with adjusted `n_neighbors` for smallest classes.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame or np.array): Features.\n",
    "        y (pd.Series or np.array): Labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Resampled X and y.\n",
    "    \"\"\"\n",
    "    # Preprocess largest class\n",
    "    X, y = preprocess_largest_class(X, y)\n",
    "    \n",
    "    # Dynamically determine n_neighbors based on smallest class\n",
    "    class_counts = Counter(y)\n",
    "    min_class_size = min(class_counts.values())\n",
    "    n_neighbors = min(5, min_class_size - 1)  # Adjust neighbors to fit smallest class\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89aebfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:36:03.396098Z",
     "iopub.status.busy": "2024-12-07T00:36:03.395733Z",
     "iopub.status.idle": "2024-12-07T00:36:03.412082Z",
     "shell.execute_reply": "2024-12-07T00:36:03.411027Z"
    },
    "papermill": {
     "duration": 0.02288,
     "end_time": "2024-12-07T00:36:03.414234",
     "exception": false,
     "start_time": "2024-12-07T00:36:03.391354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(train_data_path, test_data_path, is_string_labels = False, label_mapping = None):\n",
    "\n",
    "    # Initialize the one-hot encoder for the target\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Load Training Data\n",
    "    train_data = import_data(train_data_path)\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "    # Resample Training Data\n",
    "    X = train_data.iloc[:, :-1]\n",
    "    y = train_data.iloc[:, -1]\n",
    "    X_resampled, y_resampled = apply_smote_dynamic_with_reduction(X, y)\n",
    "\n",
    "    # Prepare Training Data\n",
    "    if (is_string_labels):\n",
    "        y_resampled = y_resampled.map(label_mapping)\n",
    "    train_X = X_resampled.to_numpy()\n",
    "    train_y = y_resampled.to_numpy()\n",
    "    train_y = encoder.fit_transform(train_y.reshape(-1, 1))\n",
    "\n",
    "    # Perform a stratified split into train and validation sets (80% train, 20% validation)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)\n",
    "\n",
    "    # Load and Prepare Test Data (this will not be used in training)\n",
    "    test_data = import_data(test_data_path)\n",
    "    test_data = test_data.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "    if (is_string_labels):\n",
    "        test_data['label'] = test_data['label'].map(label_mapping)\n",
    "    test_X = test_data.drop(columns=['label']).values\n",
    "    test_y = test_data['label'].values\n",
    "    test_y = encoder.transform(test_y.reshape(-1, 1))\n",
    "\n",
    "    # Parameters for Random Feature Combination\n",
    "    num_combinations = 20  # Number of random column combinations\n",
    "    combination_size = 3   # Number of columns in each combination\n",
    "\n",
    "    # EarlyStopping Callback (optional, to avoid overfitting)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Number of runs for averaging results\n",
    "    num_runs = 5\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    metrics_storage = defaultdict(list)\n",
    "\n",
    "    # Train the Model with Validation Split N tines for more accurate metrics\n",
    "    #print(\"Verbose output only for first run...\")\n",
    "    verbose_run = 0\n",
    "    for run in range(num_runs):\n",
    "        \n",
    "        # Model is defined separately in each run, since the random combination layers\n",
    "        # must be randomly initialized each time. Otherwise, the \"random\" indices stay the same\n",
    "        # throughout all runs\n",
    "        input_layer = Input(shape=(X_train.shape[1],))  # Input shape from the training data\n",
    "        feature_layer = create_random_combination_layer(input_layer, combination_size, num_combinations, X_train.shape[1])\n",
    "        hidden_layer = Dense(128, activation='relu')(feature_layer)\n",
    "        hidden_layer = Dropout(0.5)(hidden_layer)\n",
    "        output_layer = Dense(test_y.shape[1], activation='softmax')(hidden_layer)\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(f\"Run {run + 1}/{num_runs} started...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            epochs=1000, \n",
    "            batch_size=int(X_train.shape[0] * 0.01), \n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=verbose_run\n",
    "        )\n",
    "        verbose_run = 0 # Suppress detailed output for multiple runs\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
    "        y_pred = model.predict(test_X, verbose=0)\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        y_true_classes = test_y.argmax(axis=1)\n",
    "\n",
    "        # Compute metrics\n",
    "        balanced_acc = balanced_accuracy_score(y_true_classes, y_pred_classes)\n",
    "        roc_auc = roc_auc_score(test_y, y_pred, multi_class='ovr')  # `test_y` is fine here for AUC\n",
    "        pr_auc = average_precision_score(test_y, y_pred, average='weighted')\n",
    "        f2 = fbeta_score(y_true_classes, y_pred_classes, beta=2, average='weighted')\n",
    "        mcc = matthews_corrcoef(y_true_classes, y_pred_classes)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_storage['test_loss'].append(test_loss)\n",
    "        metrics_storage['test_accuracy'].append(test_acc)\n",
    "        metrics_storage['balanced_accuracy'].append(balanced_acc)\n",
    "        metrics_storage['roc_auc'].append(roc_auc)\n",
    "        metrics_storage['pr_auc'].append(pr_auc)\n",
    "        metrics_storage['f2'].append(f2)\n",
    "        metrics_storage['mcc'].append(mcc)\n",
    "\n",
    "        # Store classification report metrics\n",
    "        report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "        for label, values in report.items():\n",
    "            # Check if the value is a dictionary (e.g., 'precision', 'recall', 'f1-score')\n",
    "            if isinstance(values, dict):\n",
    "                for metric, value in values.items():\n",
    "                    metrics_storage[f\"{label}_{metric}\"].append(value)\n",
    "            else:\n",
    "                # Handle scalar values (like 'accuracy')\n",
    "                metrics_storage[label].append(values)\n",
    "\n",
    "    # Average the metrics over all runs\n",
    "    print(\"\\nAggregated Metrics:\")\n",
    "    for metric, values in metrics_storage.items():\n",
    "        avg_value = np.mean(values)\n",
    "        print(f\"{metric}: {avg_value:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e7c67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:36:03.421394Z",
     "iopub.status.busy": "2024-12-07T00:36:03.421018Z",
     "iopub.status.idle": "2024-12-07T00:41:06.016748Z",
     "shell.execute_reply": "2024-12-07T00:41:06.015645Z"
    },
    "papermill": {
     "duration": 302.605891,
     "end_time": "2024-12-07T00:41:06.023099",
     "exception": false,
     "start_time": "2024-12-07T00:36:03.417208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 3.54 MB\n",
      "Memory usage after optimization is: 0.84 MB\n",
      "Decreased by 76.2%\n",
      "Memory usage of dataframe is 0.89 MB\n",
      "Memory usage after optimization is: 0.21 MB\n",
      "Decreased by 76.2%\n",
      "Run 1/5 started...\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 0.6491\n",
      "test_accuracy: 0.7138\n",
      "balanced_accuracy: 0.7252\n",
      "roc_auc: 0.9108\n",
      "pr_auc: 0.9320\n",
      "f2: 0.7198\n",
      "mcc: 0.6710\n",
      "0_precision: 0.9722\n",
      "0_recall: 0.6823\n",
      "0_f1-score: 0.7338\n",
      "0_support: 9117.0000\n",
      "1_precision: 0.4627\n",
      "1_recall: 0.8600\n",
      "1_f1-score: 0.5041\n",
      "1_support: 10.0000\n",
      "2_precision: 0.2560\n",
      "2_recall: 0.6529\n",
      "2_f1-score: 0.3227\n",
      "2_support: 34.0000\n",
      "3_precision: 0.8364\n",
      "3_recall: 0.8031\n",
      "3_f1-score: 0.7619\n",
      "3_support: 1781.0000\n",
      "4_precision: 0.8212\n",
      "4_recall: 0.9115\n",
      "4_f1-score: 0.8345\n",
      "4_support: 653.0000\n",
      "5_precision: 0.4133\n",
      "5_recall: 0.5000\n",
      "5_f1-score: 0.4076\n",
      "5_support: 2.0000\n",
      "6_precision: 0.1428\n",
      "6_recall: 0.6667\n",
      "6_f1-score: 0.2114\n",
      "6_support: 3.0000\n",
      "accuracy: 0.7138\n",
      "macro avg_precision: 0.5578\n",
      "macro avg_recall: 0.7252\n",
      "macro avg_f1-score: 0.5394\n",
      "macro avg_support: 11600.0000\n",
      "weighted avg_precision: 0.9400\n",
      "weighted avg_recall: 0.7138\n",
      "weighted avg_f1-score: 0.7422\n",
      "weighted avg_support: 11600.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"/kaggle/input/ma-datasets/shuttle_train.csv\", \"/kaggle/input/ma-datasets/shuttle_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233c0a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:41:06.031380Z",
     "iopub.status.busy": "2024-12-07T00:41:06.031001Z",
     "iopub.status.idle": "2024-12-07T01:11:06.445434Z",
     "shell.execute_reply": "2024-12-07T01:11:06.444302Z"
    },
    "papermill": {
     "duration": 1800.424147,
     "end_time": "2024-12-07T01:11:06.450533",
     "exception": false,
     "start_time": "2024-12-07T00:41:06.026386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 195.04 MB\n",
      "Memory usage after optimization is: 48.32 MB\n",
      "Decreased by 75.2%\n",
      "Memory usage of dataframe is 48.76 MB\n",
      "Memory usage after optimization is: 12.08 MB\n",
      "Decreased by 75.2%\n",
      "Run 1/5 started...\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 1.6250\n",
      "test_accuracy: 0.2804\n",
      "balanced_accuracy: 0.3385\n",
      "roc_auc: 0.6846\n",
      "pr_auc: 0.4691\n",
      "f2: 0.2765\n",
      "mcc: 0.1305\n",
      "0_precision: 0.3520\n",
      "0_recall: 0.2186\n",
      "0_f1-score: 0.2480\n",
      "0_support: 42368.0000\n",
      "1_precision: 0.6329\n",
      "1_recall: 0.3116\n",
      "1_f1-score: 0.3883\n",
      "1_support: 56661.0000\n",
      "2_precision: 0.1574\n",
      "2_recall: 0.3891\n",
      "2_f1-score: 0.1758\n",
      "2_support: 7151.0000\n",
      "3_precision: 0.0396\n",
      "3_recall: 0.6601\n",
      "3_f1-score: 0.0701\n",
      "3_support: 549.0000\n",
      "4_precision: 0.0402\n",
      "4_recall: 0.2891\n",
      "4_f1-score: 0.0657\n",
      "4_support: 1899.0000\n",
      "5_precision: 0.0773\n",
      "5_recall: 0.1354\n",
      "5_f1-score: 0.0900\n",
      "5_support: 3473.0000\n",
      "6_precision: 0.1826\n",
      "6_recall: 0.3655\n",
      "6_f1-score: 0.2120\n",
      "6_support: 4102.0000\n",
      "accuracy: 0.2804\n",
      "macro avg_precision: 0.2117\n",
      "macro avg_recall: 0.3385\n",
      "macro avg_f1-score: 0.1786\n",
      "macro avg_support: 116203.0000\n",
      "weighted avg_precision: 0.4562\n",
      "weighted avg_recall: 0.2804\n",
      "weighted avg_f1-score: 0.3022\n",
      "weighted avg_support: 116203.0000\n"
     ]
    }
   ],
   "source": [
    "run_model(\"/kaggle/input/ma-datasets/covtype_train.csv\", \"/kaggle/input/ma-datasets/covtype_test.csv\", is_string_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0708c6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T01:11:06.459949Z",
     "iopub.status.busy": "2024-12-07T01:11:06.459547Z",
     "iopub.status.idle": "2024-12-07T04:14:54.532946Z",
     "shell.execute_reply": "2024-12-07T04:14:54.529836Z"
    },
    "papermill": {
     "duration": 11028.089213,
     "end_time": "2024-12-07T04:14:54.543591",
     "exception": false,
     "start_time": "2024-12-07T01:11:06.454378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 789.51 MB\n",
      "Memory usage after optimization is: 196.60 MB\n",
      "Decreased by 75.1%\n",
      "Memory usage of dataframe is 197.38 MB\n",
      "Memory usage after optimization is: 49.15 MB\n",
      "Decreased by 75.1%\n",
      "Run 1/5 started...\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 2.8790\n",
      "test_accuracy: 0.0132\n",
      "balanced_accuracy: 0.1453\n",
      "roc_auc: 0.5809\n",
      "pr_auc: 0.9313\n",
      "f2: 0.0095\n",
      "mcc: 0.0863\n",
      "0_precision: 0.3999\n",
      "0_recall: 0.0022\n",
      "0_f1-score: 0.0044\n",
      "0_support: 194557.0000\n",
      "1_precision: 0.2936\n",
      "1_recall: 0.4213\n",
      "1_f1-score: 0.3173\n",
      "1_support: 3178.0000\n",
      "2_precision: 0.0000\n",
      "2_recall: 0.0000\n",
      "2_f1-score: 0.0000\n",
      "2_support: 2496.0000\n",
      "3_precision: 0.0302\n",
      "3_recall: 0.3530\n",
      "3_f1-score: 0.0516\n",
      "3_support: 2083.0000\n",
      "4_precision: 0.0585\n",
      "4_recall: 0.0834\n",
      "4_f1-score: 0.0687\n",
      "4_support: 463.0000\n",
      "5_precision: 0.0253\n",
      "5_recall: 0.1664\n",
      "5_f1-score: 0.0429\n",
      "5_support: 441.0000\n",
      "6_precision: 0.0018\n",
      "6_recall: 0.0245\n",
      "6_f1-score: 0.0034\n",
      "6_support: 204.0000\n",
      "7_precision: 0.0002\n",
      "7_recall: 0.2000\n",
      "7_f1-score: 0.0004\n",
      "7_support: 196.0000\n",
      "8_precision: 0.0021\n",
      "8_recall: 0.2000\n",
      "8_f1-score: 0.0041\n",
      "8_support: 53.0000\n",
      "9_precision: 0.0019\n",
      "9_recall: 0.2000\n",
      "9_f1-score: 0.0038\n",
      "9_support: 11.0000\n",
      "10_precision: 0.0000\n",
      "10_recall: 0.0000\n",
      "10_f1-score: 0.0000\n",
      "10_support: 6.0000\n",
      "11_precision: 0.2015\n",
      "11_recall: 0.4000\n",
      "11_f1-score: 0.2030\n",
      "11_support: 4.0000\n",
      "12_precision: 0.0001\n",
      "12_recall: 0.2000\n",
      "12_f1-score: 0.0002\n",
      "12_support: 4.0000\n",
      "13_precision: 0.0105\n",
      "13_recall: 0.1000\n",
      "13_f1-score: 0.0190\n",
      "13_support: 2.0000\n",
      "14_precision: 0.0000\n",
      "14_recall: 0.0000\n",
      "14_f1-score: 0.0000\n",
      "14_support: 2.0000\n",
      "15_precision: 0.0000\n",
      "15_recall: 0.0000\n",
      "15_f1-score: 0.0000\n",
      "15_support: 2.0000\n",
      "16_precision: 0.0000\n",
      "16_recall: 0.2000\n",
      "16_f1-score: 0.0000\n",
      "16_support: 1.0000\n",
      "17_precision: 0.0200\n",
      "17_recall: 0.1000\n",
      "17_f1-score: 0.0333\n",
      "17_support: 2.0000\n",
      "18_precision: 0.0000\n",
      "18_recall: 0.0000\n",
      "18_f1-score: 0.0000\n",
      "18_support: 1.0000\n",
      "19_precision: 0.0000\n",
      "19_recall: 0.2000\n",
      "19_f1-score: 0.0000\n",
      "19_support: 1.0000\n",
      "20_precision: 0.0000\n",
      "20_recall: 0.2000\n",
      "20_f1-score: 0.0000\n",
      "20_support: 1.0000\n",
      "accuracy: 0.0132\n",
      "macro avg_precision: 0.0498\n",
      "macro avg_recall: 0.1453\n",
      "macro avg_f1-score: 0.0358\n",
      "macro avg_support: 203708.0000\n",
      "weighted avg_precision: 0.3870\n",
      "weighted avg_recall: 0.0132\n",
      "weighted avg_f1-score: 0.0100\n",
      "weighted avg_support: 203708.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'normal.': 0, 'satan.': 1, 'ipsweep.': 2, 'portsweep.': 3, 'nmap.': 4,\n",
    "    'back.': 5, 'warezclient.': 6, 'teardrop.': 7, 'pod.': 8, 'guess_passwd.': 9,\n",
    "    'buffer_overflow.': 10, 'land.': 11, 'warezmaster.': 12, 'imap.': 13, 'rootkit.': 14,\n",
    "    'loadmodule.': 15, 'multihop.': 16, 'ftp_write.': 17, 'phf.': 18, 'perl.': 19, 'spy.': 20\n",
    "}\n",
    "\n",
    "run_model(\"/kaggle/input/ma-datasets/kdd_train.csv\", \"/kaggle/input/ma-datasets/kdd_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c8e2f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T04:14:54.559639Z",
     "iopub.status.busy": "2024-12-07T04:14:54.558619Z",
     "iopub.status.idle": "2024-12-07T04:27:45.772731Z",
     "shell.execute_reply": "2024-12-07T04:27:45.771197Z"
    },
    "papermill": {
     "duration": 771.233435,
     "end_time": "2024-12-07T04:27:45.782495",
     "exception": false,
     "start_time": "2024-12-07T04:14:54.549060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 100.68 MB\n",
      "Memory usage after optimization is: 25.05 MB\n",
      "Decreased by 75.1%\n",
      "Memory usage of dataframe is 25.17 MB\n",
      "Memory usage after optimization is: 6.26 MB\n",
      "Decreased by 75.1%\n",
      "Run 1/5 started...\n",
      "Run 2/5 started...\n",
      "Run 3/5 started...\n",
      "Run 4/5 started...\n",
      "Run 5/5 started...\n",
      "\n",
      "Aggregated Metrics:\n",
      "test_loss: 1.9212\n",
      "test_accuracy: 0.0954\n",
      "balanced_accuracy: 0.2912\n",
      "roc_auc: 0.6964\n",
      "pr_auc: 0.8042\n",
      "f2: 0.0934\n",
      "mcc: 0.1287\n",
      "0_precision: 0.5846\n",
      "0_recall: 0.0605\n",
      "0_f1-score: 0.1094\n",
      "0_support: 26862.0000\n",
      "1_precision: 0.4006\n",
      "1_recall: 0.1591\n",
      "1_f1-score: 0.2089\n",
      "1_support: 2657.0000\n",
      "2_precision: 0.4373\n",
      "2_recall: 0.7725\n",
      "2_f1-score: 0.4162\n",
      "2_support: 908.0000\n",
      "3_precision: 0.0347\n",
      "3_recall: 0.0747\n",
      "3_f1-score: 0.0469\n",
      "3_support: 522.0000\n",
      "4_precision: 0.0215\n",
      "4_recall: 0.1420\n",
      "4_f1-score: 0.0279\n",
      "4_support: 293.0000\n",
      "5_precision: 0.0448\n",
      "5_recall: 0.5100\n",
      "5_f1-score: 0.0765\n",
      "5_support: 269.0000\n",
      "6_precision: 0.0173\n",
      "6_recall: 0.2517\n",
      "6_f1-score: 0.0266\n",
      "6_support: 116.0000\n",
      "7_precision: 0.0044\n",
      "7_recall: 0.2226\n",
      "7_f1-score: 0.0085\n",
      "7_support: 53.0000\n",
      "8_precision: 0.0048\n",
      "8_recall: 0.4273\n",
      "8_f1-score: 0.0094\n",
      "8_support: 44.0000\n",
      "accuracy: 0.0954\n",
      "macro avg_precision: 0.1722\n",
      "macro avg_recall: 0.2912\n",
      "macro avg_f1-score: 0.1034\n",
      "macro avg_support: 31724.0000\n",
      "weighted avg_precision: 0.5423\n",
      "weighted avg_recall: 0.0954\n",
      "weighted avg_f1-score: 0.1239\n",
      "weighted avg_support: 31724.0000\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    'Normal': 0, 'Darknet_Audio-Streaming': 1, 'Darknet_Chat': 2, 'Darknet_File-Transfer': 3, 'Darknet_VOIP': 4,\n",
    "    'Darknet_Video-Streaming': 5, 'Darknet_Email': 6, 'Darknet_Browsing': 7, 'Darknet_P2P': 8\n",
    "}\n",
    "\n",
    "run_model(\"/kaggle/input/ma-datasets/darknet_train.csv\", \"/kaggle/input/ma-datasets/darknet_test.csv\", is_string_labels = True, label_mapping = labels_map)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6246813,
     "sourceId": 10123278,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13923.981732,
   "end_time": "2024-12-07T04:27:49.162024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T00:35:45.180292",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
